{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrAyOX0HfCrz"
   },
   "source": [
    "To complete the exercise focus on the parts that are mentioned in questions. You don't need to understand everything to its fullest here. Even if it's nice to know. The following file loads the english/german sentence pairs and prints out an example of what a pair looks like. Note that for fast training we cut the sentences down to pairs where the english text starts with a personal pronoun and the correspoding form of \"to be\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "igtgOuQSEqEZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from load_languages import prepareData\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 195847 sentence pairs\n",
      "Trimmed to 11727 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 7046\n",
      "ger 4484\n",
      "['Ich bin heute in Tokio.', 'I am in Tokyo today.']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('ger', 'eng', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mir ist gerade richtig langweilig.', \"I'm really bored right now.\"]\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-pedfJtOEZD"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ciNc4p42fS5_"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src), tgt)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        return self.encoder(self.src_embed(src))\n",
    "    \n",
    "    def decode(self, memory, tgt):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "sNcJlQHygpGT"
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([module for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "19_UC5JljAcV"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"Pass the input through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "z3vWNYA_jMbh"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features)).to(device)\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features)).to(device)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "uEMdUlL3jfXG"
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "d7xSGjgnkSCH"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = [SublayerConnection(size, dropout) for i in range(2)]\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-23H2KFLk27a"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder\"\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7M3Noq7wlCvl"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x\n",
    "        , mask=subsequent_mask(x.shape[-2])))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(m, m, x))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9fPOqOQe15D"
   },
   "source": [
    "**Exercise 1a)** Complete the attention method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kiACIq5Vlzgd"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-49471a1ada56>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-49471a1ada56>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    d_k =\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def attention(value, key, query, mask = None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    # fill in the gaps\n",
    "    d_k = \n",
    "    # what is inside the softmax\n",
    "    scores = \n",
    "    \n",
    "    if mask is not None:\n",
    "        # change all the values where the mask equals 0 to minus infinity (-1e9 is enough)\n",
    "        scores = scores.masked_fill((mask == 0).to(device), -1e9)  \n",
    "    # apply softmax to the right dimension\n",
    "    p_attn = \n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    \n",
    "    # multiply with value\n",
    "    attention = \n",
    "    \n",
    "    return attention, p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMvDOtHgtH2l"
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, value, key, query, mask = None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        value, key, query = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (value, key, query))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(value, key, query, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Gvrm5iseJhd"
   },
   "source": [
    "**Exercise 1d)** Visualize the mask and explain what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2P0eJrrry7h"
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOrELpc4EgmE"
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxbblmhOVCv0"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implements the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdmdRkFnVN5H"
   },
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    print(tgt_vocab)\n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YqhHqoAHlDo"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    # converts a string into a tensor\n",
    "    # the options for lang are either input_lang or output_lang\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    sen_len = len(indexes)\n",
    "    # fill the tensor with EOS_tokens at the end, s.t. it has length 10\n",
    "    indexes.extend([EOS_token for _ in range(10-sen_len)])\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    input_tensor = input_tensor.permute(1,0)\n",
    "    target_tensor = target_tensor.permute(1,0)\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def outputTensorFromTGT(tgt):\n",
    "    # converts the tgt to an output tensor, with which we can compute the loss\n",
    "    # think about what happens here. 4484 =  output_lang.n_words is the number of german words in our dictionary\n",
    "    tgt_list = []\n",
    "    bs = tgt.shape[0]\n",
    "    for i in range(bs):\n",
    "        sentdist_tensor = torch.cat([torch.from_numpy(np.eye(1,output_lang.n_words,index.item())).unsqueeze(0)\n",
    "                           for index in tgt[i,:]], dim = 1)\n",
    "        tgt_list.append(sentdist_tensor)\n",
    "    return torch.cat(tgt_list, dim = 0).float()\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "def train(pair, batch_size, sample = False):\n",
    "    src, tgt = pair\n",
    "    src.to(device)\n",
    "    tgt.to(device)\n",
    "    tgt_tensor = outputTensorFromTGT(tgt).to(device)\n",
    "    decoder_input = torch.tensor([[SOS_token] for _ in range(batch_size)], device=device)\n",
    "    if not sample:\n",
    "        decoder_input = torch.cat([decoder_input, tgt], dim = 1)\n",
    "    else:\n",
    "        cat_list = [decoder_input]\n",
    "        gen_list = []\n",
    "    memory = transformer.encode(src)\n",
    "    if sample:\n",
    "        for i in range(MAX_LENGTH):\n",
    "          decoder_output = transformer.decode(memory, decoder_input)\n",
    "          gen = transformer.generator(decoder_output[:,-1])\n",
    "          gen_list.append(gen.unsqueeze(1))\n",
    "          pred = (gen.argmax(dim = 1)).unsqueeze(1)\n",
    "          cat_list.append(pred)\n",
    "          decoder_input = torch.cat(cat_list, dim = 1)\n",
    "        output = torch.cat(gen_list, dim = 1)\n",
    "    else:\n",
    "        decoder_output = transformer.decode(memory, decoder_input)\n",
    "        gen = transformer.generator(decoder_output[:,:10,:])\n",
    "        output = gen\n",
    "    loss = criterion(output, tgt_tensor)\n",
    "    return loss, decoder_input\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9vypkIXVqz_"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transformer = make_model(input_lang.n_words, output_lang.n_words, 2 , d_model = 512, d_ff = 512, h = 4)\n",
    "transformer.to(device)\n",
    "\n",
    "optimizer = optim.Adam(transformer.parameters())\n",
    "criterion = nn.KLDivLoss(reduction = 'batchmean')\n",
    "\n",
    "n_pairs = 64000 # number of training pairs\n",
    "batch_size = 512 \n",
    "\n",
    "#--------------\n",
    "# Create Batch\n",
    "#--------------\n",
    "\n",
    "\n",
    "training_pairs = []\n",
    "for i in range(n_pairs // batch_size):\n",
    "    batch_pairs = [tensorsFromPair(random.choice(pairs)) for _ in range(batch_size)] \n",
    "    batch_input  = torch.cat([pair[0] for pair in batch_pairs], dim = 0)\n",
    "    batch_tgt = torch.cat([pair[1] for pair in batch_pairs], dim = 0)\n",
    "    training_pairs.append((batch_input, batch_tgt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3nbew_TGn-p"
   },
   "outputs": [],
   "source": [
    "def evaluate(pair, showTgt = False, print_ = True):\n",
    "  transformer.eval()      # disable dropout\n",
    "  inputs = tensorsFromPair(pair)\n",
    "  if print_:\n",
    "      print(\"Example: Input -> Output:\")\n",
    "      print(pair[0])\n",
    "      output_sent ='> '\n",
    "      if showTgt:\n",
    "            print('- '+pair[1])\n",
    "  else:\n",
    "      output_sent = ''\n",
    "  _ , output = train(inputs, batch_size = 1, sample = True)\n",
    "  \n",
    "  for word in output.squeeze(0):\n",
    "    if(word.item() == EOS_token):\n",
    "        # don't print EOS at the end\n",
    "        break\n",
    "    if(word.item() != SOS_token):\n",
    "        # don't print SOS at the beginning\n",
    "        output_sent += output_lang.index2word[word.item()]+' '\n",
    "  return (output_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4mooxOQWMHa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "def timer(progress, iterations):\n",
    "    now = time.time()-start_time\n",
    "    now = now*iterations/progress\n",
    "    std = now // 3600\n",
    "    min = (now // 60) % 60\n",
    "    sec = now % 60\n",
    "    return int(std), int(min), int(sec)\n",
    "\n",
    "\n",
    "total_loss = 0\n",
    "log = 25       # when to show training status\n",
    "epochs = 5     # how many epochs to train\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    for i,pair in enumerate(training_pairs):\n",
    "        transformer.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss, _ = train(pair, batch_size = batch_size)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        losses.append(loss)\n",
    "        if i% log == log-1:\n",
    "            print(\"[Epoch: {}][{}/{}][Loss: {}][Time per epoch: {:02d}:{:02d}:{:02d}]\".format(\n",
    "                epoch+1, i+1, int(n_pairs/batch_size), total_loss/log, *timer(i+1,int(n_pairs/batch_size))))\n",
    "            total_loss = 0\n",
    "            pair = random.choice(pairs)\n",
    "            print(evaluate(pair))\n",
    "    start_time = time.time()\n",
    "print('Loss plot:')\n",
    "plt.plot(losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kkf7VW7i5ued"
   },
   "outputs": [],
   "source": [
    "pair = random.choice(pairs)\n",
    "print(evaluate(pair, showTgt = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQVInITOo4V-"
   },
   "source": [
    "**Exercise 1c)** Translate your own german sentence. You can make use of the evaluate function to achive that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZZHZH-DZGjk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib3sNDkvajbQ"
   },
   "source": [
    "**Exercise 2b)** Print the distance from your word to sister in embedding space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjFm5Z4li9By"
   },
   "outputs": [],
   "source": [
    "word1 = \"woman\"\n",
    "word2 = \"man\"\n",
    "word3 = \"brother\"\n",
    "word4 = \"sister\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PG4HbnWmgZzj"
   },
   "source": [
    "**Exercise 2a)** Complete the following code. Be aware that there will be 10 values for each word even if the input sentence is shorter than 10 words. Thats because the sentences get filled with EOS_tokens at the end such that they all are the same size. Set the tick_label of the bar plot to be the input sentences words (use string.split() to convert strings to lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pH2TlFlLZyVZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "output = evaluate(pair, showTgt = True, print_ = False)\n",
    "sentence = pair[0].split()\n",
    "which_word = 3\n",
    "print('Output sentence: {}'.format(output))\n",
    "print(output.split()[which_word],':')\n",
    "for i in range(4): \n",
    "    \n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
