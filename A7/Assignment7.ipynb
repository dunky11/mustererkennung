{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo9GWxKgTN1h"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.347720Z",
     "start_time": "2018-11-29T11:28:47.572823Z"
    },
    "id": "V7XaSv5wTN1i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.data import lfw_subset\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax8ea49_bkdb"
   },
   "source": [
    "### Load the spam dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.406520Z",
     "start_time": "2018-11-29T11:28:48.349530Z"
    },
    "id": "sT2Hk2k-TN1i"
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('spambase.data', header=None))\n",
    "\n",
    "X = data[:,:-1] # features\n",
    "y = data[:,-1] # Last column is label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def gini(y_true, c):\n",
    "    \"\"\"\n",
    "    For simplicity reasons this assumes that there are only 2 classes\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    p_mk = np.mean(y_true == c)\n",
    "\n",
    "    return 2 * p_mk * (1 - p_mk)\n",
    "\n",
    "class LeafNode():\n",
    "    def fit(self, c):\n",
    "        self.c = c\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.c\n",
    "\n",
    "class InternalNodeBase():\n",
    "    \"\"\" \n",
    "    Functions which don't differ between ordinary decision trees and\n",
    "    viola jones decision tree\n",
    "    \"\"\"\n",
    "    def find_c(self, y):\n",
    "        \"\"\"\n",
    "        For simplicity reasons this assumes that there are only 2 classes\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        zeros = np.sum(y == 0)\n",
    "        ones = np.sum(y == 1)\n",
    "        if ones > zeros:\n",
    "            return 1\n",
    "        return 0\n",
    "        \n",
    "    def is_pure(self, y):\n",
    "        y = np.array(y)\n",
    "        if np.sum(y == 0) == y.shape[0] or np.sum(y == 1) == y.shape[0]:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "class InternalNode(InternalNodeBase):\n",
    "    \"\"\"\n",
    "    Node of decision tree, which accepts tabular data\n",
    "    \"\"\"\n",
    "    def fit(self, x, y, depth, max_depth):\n",
    "        m, n = x.shape\n",
    "        # columns are j, split_index, loss_total\n",
    "        split_infos = []\n",
    "            \n",
    "        for j in range(n):\n",
    "            # sort rows by feature j in ascending order\n",
    "            sorted_indices = x[:,j].argsort()\n",
    "            x, y = x[sorted_indices], y[sorted_indices]\n",
    "            for split_index in range(0, m - 1):\n",
    "                \n",
    "                y_top_split = y[:split_index + 1]\n",
    "                y_bottom_split = y[split_index + 1:]\n",
    "                \n",
    "                if y_top_split.shape[0] == 0:\n",
    "                    raise Exception(\"Error 1\")\n",
    "                    \n",
    "                if y_bottom_split.shape[0] == 0:\n",
    "                    raise Exception(\"Error 2\")\n",
    "                \n",
    "                c1 = self.find_c(y_top_split)\n",
    "                c2 = self.find_c(y_bottom_split)\n",
    "                \n",
    "                loss_1 = gini(y_top_split, c1)\n",
    "                loss_2 = gini(y_bottom_split, c2)\n",
    "                \n",
    "                # use weighted average which had better results\n",
    "                loss_total = (y_top_split.shape[0] / m) * loss_1  + (y_bottom_split.shape[0] / m) * loss_2\n",
    "                \n",
    "                row = np.array([j, split_index, loss_total])\n",
    "                split_infos.append(row)\n",
    "                \n",
    "        split_infos = np.array(split_infos)\n",
    "        best_split_idx = np.argmin(split_infos[:,-1], axis=0)\n",
    "        best_split = split_infos[best_split_idx]\n",
    "        self.j = int(best_split[0])\n",
    "        split_index = int(best_split[1])\n",
    "        \n",
    "        sorted_indices = x[:,j].argsort()\n",
    "        x, y = x[sorted_indices], y[sorted_indices]\n",
    "        \n",
    "        x_top_split, y_top_split = x[:split_index + 1], y[:split_index + 1]\n",
    "        x_bottom_split, y_bottom_split = x[split_index + 1:], y[split_index + 1:]\n",
    "        \n",
    "        self.z = (x_top_split[-1, self.j] + x_bottom_split[0, self.j]) / 2\n",
    "        \n",
    "        if self.is_pure(y_top_split) or x_top_split.shape[0] <= 2 or depth >= max_depth:\n",
    "            self.left_child = LeafNode()\n",
    "            c = self.find_c(y_top_split)\n",
    "            self.left_child.fit(c)\n",
    "        else:\n",
    "            self.left_child = InternalNode()\n",
    "            self.left_child.fit(x_top_split, y_top_split, depth + 1, max_depth)\n",
    "            \n",
    "        if self.is_pure(y_bottom_split) or x_bottom_split.shape[0] <= 2 or depth >= max_depth:\n",
    "            self.right_child = LeafNode()\n",
    "            c = self.find_c(y_bottom_split)\n",
    "            self.right_child.fit(c)\n",
    "        else:\n",
    "            self.right_child = InternalNode()\n",
    "            self.right_child.fit(x_bottom_split, y_bottom_split, depth + 1, max_depth)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if x[self.j] <= self.z:\n",
    "            return self.left_child.predict(x)\n",
    "        return self.right_child.predict(x)\n",
    "    \n",
    "class DecisionTreeClassifier():\n",
    "    \"\"\"\n",
    "    Basically just holds the root node of the tree which starts the recursion\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, x, y, features):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        self.root = InternalNode()\n",
    "        self.root.fit(x, y, 1, self.max_depth)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_preds = []\n",
    "        for sample in x:\n",
    "            y_pred = self.root.predict(sample)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Delete later\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class AdaBoost():\n",
    "    def __init__(self, num_trees, max_depth):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "            \n",
    "    def fit(self, x, y, features=None):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        self.trees = []\n",
    "        self.says = []\n",
    "        for i in tqdm(range(self.num_trees)):\n",
    "            # sample weights will always add up to one\n",
    "            sample_weights = np.ones((y.shape[0], )) / y.shape[0]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(x, y, features)\n",
    "            y_pred = tree.predict(x)\n",
    "            error = self.calculate_error(y, y_pred, sample_weights)\n",
    "            say = self.error_to_say(error)\n",
    "            sample_weights = self.update_sample_weights(y, y_pred, say, sample_weights)\n",
    "            x, y = self.weighted_dataset(x, y, sample_weights)\n",
    "            self.trees.append(tree)\n",
    "            self.says.append(say)\n",
    "            \n",
    "        self.says = np.array(self.says)\n",
    "            \n",
    "    def weighted_dataset(self, x, y, sample_weights):\n",
    "        x_new, y_new = [], []\n",
    "        sample_weights_cum = np.cumsum(sample_weights)\n",
    "        rand = np.random.uniform(low=0.0, high=1.0, size=(x.shape[0], ))\n",
    "        for rand_el in rand:\n",
    "            for i, cum_weight in enumerate(sample_weights_cum):\n",
    "                if cum_weight >= rand_el:\n",
    "                    x_new.append(x[i])\n",
    "                    y_new.append(y[i])\n",
    "                    break\n",
    "        return np.array(x_new), np.array(y_new)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def calculate_error(self, y_true, y_pred, sample_weights):\n",
    "        \"\"\"\n",
    "        How much say a stump has is calculated by it's error, which is just the\n",
    "        sum of the sample_weights for the missclassified samples.\n",
    "        The error is always between 0 and 1 because the sample weights add up to one.\n",
    "        0 is the lowest possible error and 1 is the highest.\n",
    "        \"\"\"\n",
    "        error_idx = y_true != y_pred\n",
    "        return np.sum(sample_weights[error_idx])\n",
    "    \n",
    "    def error_to_say(self, error):\n",
    "        \"\"\"\n",
    "        Transforms the error a stump has into it's say which will be used\n",
    "        to weight the importance of one stumps prediction in the final prediction.\n",
    "        The say is ~ between 3.5 and -3.5 which means a stumps prediction can actually\n",
    "        be weighted negaively in the final prediction if it error is high.\n",
    "        If error is 0 we will have division by 0, if error is 1, we will have log(0)\n",
    "        which is also not possible. So a small eps is added / subtracted from the \n",
    "        error to keep calculations stable.\n",
    "        \"\"\"\n",
    "        eps = 10 ** -10\n",
    "        if error == 0:\n",
    "            error = error + eps\n",
    "        elif error == 1:\n",
    "            error = error - eps\n",
    "        return 0.5 * np.log((1 - error) / error)\n",
    "    \n",
    "    def update_sample_weights(self, y_true, y_pred, say, sample_weights):\n",
    "        \"\"\"\n",
    "        Updates the sample weights by scaling them based on the amount of say the stump\n",
    "        has and wether it properly classified the sample.\n",
    "        If say is high and the sample was missclassified, the sample weight will go up.\n",
    "        If say is high and the sample was propely classified, the sample weight will go down.\n",
    "        If say is low and the sample was missclassified, the sample weight will go down.\n",
    "        If say is low and the sample was properly classified, the sample weight will go up.\n",
    "        After updating the sample weights will still sum up to one.\n",
    "        \"\"\"\n",
    "        sample_weights = np.where(y_true == y_pred, \n",
    "                                  sample_weights * np.exp(-say), \n",
    "                                  sample_weights * np.exp(say))\n",
    "        # normalization so sample_weights add up to 1 again\n",
    "        sample_weights = sample_weights / np.sum(sample_weights)\n",
    "        return sample_weights\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y_preds = []\n",
    "        for sample in x:\n",
    "            votes = []\n",
    "            for tree in self.trees:\n",
    "                # decision tree expects matrix as input\n",
    "                sample = sample.reshape((1, -1))\n",
    "                votes.append(tree.predict(sample))\n",
    "            votes = np.array(votes).reshape((-1, ))\n",
    "            yes_say = np.sum(self.says[votes == 1])\n",
    "            no_say = np.sum(self.says[votes == 0])\n",
    "            if yes_say > no_say:\n",
    "                y_preds.append(1)\n",
    "            else:\n",
    "                y_preds.append(0)\n",
    "        return np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76650fdf58644b91aada991f7543b826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3.57 s, sys: 159 ms, total: 3.73 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoost(num_trees=10, max_depth=1)\n",
    "clf.fit(X_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671589921807124\n",
      "CPU times: user 64.6 ms, sys: 0 ns, total: 64.6 ms\n",
      "Wall time: 63.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to AdaBoost with depth of 2 instead of 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e50c62ce1342a48f2a7348c88f399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 6.8 s, sys: 112 ms, total: 6.91 s\n",
      "Wall time: 6.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoost(num_trees=10, max_depth=2)\n",
    "clf.fit(X_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8722849695916595\n",
      "CPU times: user 82.3 ms, sys: 0 ns, total: 82.3 ms\n",
      "Wall time: 81.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Viola-Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    \"\"\"\n",
    "    Generates dataset of 250 images of faces with labels 1 and 250 images of digits with label 0, \n",
    "    each are 25x25 pixels.\n",
    "    \"\"\"\n",
    "    face_data = lfw_subset()\n",
    "    mnist = fetch_openml('mnist_784').data[:face_data.shape[0]]\n",
    "    mnist = mnist.reshape((-1, 28, 28))\n",
    "    mnist = mnist[:,1:26, 1:26]\n",
    "    face_labels = np.ones((face_data.shape[0], ))\n",
    "    mnist_labels = np.zeros((mnist.shape[0], ))\n",
    "    x = np.vstack((face_data, mnist))\n",
    "    y = np.hstack((face_labels, mnist_labels))\n",
    "    assert(x.shape[0] == y.shape[0])\n",
    "    return x, y\n",
    "x, y = generate_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectBase():\n",
    "    def calculate_area(self, integral_img,  ul_pixel_cord, lr_pixel_cord):\n",
    "        \"\"\" Calculates the of the integral_img given by two pixel coordinates.\n",
    "        ul_pixel_cord should be outside of the calculated area.\n",
    "        lr_pixel_cord is inside of the calculated area.\n",
    "        \"\"\"\n",
    "        if ul_pixel_cord[0] < 0 or ul_pixel_cord[1] < 0:\n",
    "            A = 0\n",
    "        else:\n",
    "            A = integral_img[ul_pixel_cord[0], ul_pixel_cord[1]]\n",
    "            \n",
    "        if ul_pixel_cord[0] < 0:\n",
    "            B = 0\n",
    "        else:\n",
    "            B = integral_img[ul_pixel_cord[0], lr_pixel_cord[1]]\n",
    "            \n",
    "        if ul_pixel_cord[1] < 0:\n",
    "            C = 0\n",
    "        else:\n",
    "            C = integral_img[ul_pixel_cord[1], lr_pixel_cord[0]]\n",
    "            \n",
    "        D = integral_img[lr_pixel_cord[0], lr_pixel_cord[1]]\n",
    "        return A - B - C + D\n",
    "\n",
    "\n",
    "class TwoRect(RectBase):\n",
    "    \"\"\" Feature for Viola-Jones, which looks like:\n",
    "    -----\n",
    "    --B--\n",
    "    --W--\n",
    "    -----\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, scale_x, scale_y, img_shape):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.scale_x = scale_x\n",
    "        self.scale_y = scale_y\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def is_valid(self):\n",
    "        \"\"\"\n",
    "        Returns wether the feature fits on the image\n",
    "        \"\"\"\n",
    "        lowest_pixel = self.x + (self.scale_x * 2) - 1\n",
    "        if lowest_pixel > self.img_shape[0] - 1:\n",
    "            return False\n",
    "        most_right_pixel = self.y + self.scale_y - 1\n",
    "        if most_right_pixel > self.img_shape[1] - 1:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_pixel_cords(self):\n",
    "        black_area_ul = [self.x - 1, self.y - 1]\n",
    "        black_area_lr = [self.x + self.scale_x - 1, self.y + self.scale_y - 1]\n",
    "        white_area_ul = [self.x + self.scale_x - 1, self.y - 1]\n",
    "        white_area_lr = [self.x + (self.scale_x * 2) - 1, self.y + self.scale_y - 1]\n",
    "        return {\n",
    "            \"black_area_ul\": black_area_ul,\n",
    "            \"black_area_lr\": black_area_lr,\n",
    "            \"white_area_ul\": white_area_ul,\n",
    "            \"white_area_lr\": white_area_lr\n",
    "        }\n",
    "    \n",
    "    def apply_feature(self, integral_img):\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        black_area_sum = self.calculate_area(integral_img, pixel_cords[\"black_area_ul\"], \n",
    "                                             pixel_cords[\"black_area_lr\"])\n",
    "        white_area_sum = self.calculate_area(integral_img, pixel_cords[\"white_area_ul\"], \n",
    "                                             pixel_cords[\"white_area_lr\"])\n",
    "        return white_area_sum - black_area_sum\n",
    "    \n",
    "    def visualise_feature(self):\n",
    "        img = np.ones((self.img_shape[0], self.img_shape[1])) * 0.5\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        print(pixel_cords) \n",
    "        for x in range(pixel_cords[\"black_area_ul\"][0] + 1, pixel_cords[\"black_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"black_area_ul\"][1] + 1, pixel_cords[\"black_area_lr\"][1] + 1):\n",
    "                img[x, y] = 0\n",
    "        for x in range(pixel_cords[\"white_area_ul\"][0] + 1, pixel_cords[\"white_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"white_area_ul\"][1] + 1, pixel_cords[\"white_area_lr\"][1] + 1):\n",
    "                img[x, y] = 1\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolaJonesClassifier():\n",
    "    def __init__(self, num_trees, max_depth):\n",
    "        self.adaboost = AdaBoost(num_trees, max_depth)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        imgs = []\n",
    "        for sample in x:\n",
    "            imgs.append(self.to_integral_img(sample))\n",
    "        x = np.array(imgs)\n",
    "        features = self.generate_features(x[0].shape)\n",
    "        x = self.apply_features(x, features)\n",
    "        self.adaboost.fit(x, y)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.adaboost.predict(x)\n",
    "    \n",
    "    def apply_features(self, integral_imgs, features):\n",
    "        \"\"\"\n",
    "        Transforms the integral images into a tabular dataset of shape (num_imgs, num_features),\n",
    "        where [i, j] corresponds to the j-th feature applied to the i-th img\n",
    "        \"\"\"\n",
    "        x_new = np.zeros((integral_imgs.shape[0], len(features)))\n",
    "        for row in range(x_new.shape[0]):\n",
    "            for feature in range(len(features)):\n",
    "                x_new[row, feature] = features[feature].apply_feature(integral_imgs[row])\n",
    "        return x_new\n",
    "    \n",
    "    def to_integral_img(self, img):\n",
    "        img = img.copy()\n",
    "        for row in range(img.shape[0]):\n",
    "            for col in range(img.shape[1]):\n",
    "                new_val = img[row, col]\n",
    "                if row != 0:\n",
    "                    new_val += img[row - 1, col]\n",
    "                if col != 0:\n",
    "                    new_val += img[row, col - 1]\n",
    "                if row != 0 and col != 0:\n",
    "                    new_val -= img[row - 1, col - 1]\n",
    "                img[row, col] = new_val\n",
    "        return img\n",
    "    \n",
    "    def generate_features(self, img_shape):\n",
    "        features = []\n",
    "        for x in range(img_shape[0]):\n",
    "            for y in range(img_shape[1]):\n",
    "                for scale_x in range(1, img_shape[0]):\n",
    "                    for scale_y in range(1, img_shape[1]):\n",
    "                        feat = TwoRect(x, y, scale_x, scale_y, img_shape)\n",
    "                        if feat.is_valid():\n",
    "                            features.append(feat)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'black_area_ul': [-1, 0], 'black_area_lr': [1, 3], 'white_area_ul': [1, 0], 'white_area_lr': [3, 3]}\n",
      "[[ 1.  2.  3.  4.  5.  6.]\n",
      " [ 2.  4.  6.  8. 10. 12.]\n",
      " [ 3.  6.  9. 12. 15. 18.]\n",
      " [ 4.  8. 12. 16. 20. 24.]\n",
      " [ 5. 10. 15. 20. 25. 30.]\n",
      " [ 6. 12. 18. 24. 30. 36.]]\n",
      "0.0\n",
      "Its a valid feature\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat = TwoRect(0, 1, 2, 3, (6, 6))\n",
    "visualization = feat.visualise_feature()\n",
    "extent = (0, visualization.shape[1], visualization.shape[0], 0)\n",
    "_, ax = plt.subplots()\n",
    "ax.imshow(visualization, extent=extent, cmap='gray')\n",
    "ax.grid(color='w', linewidth=2)\n",
    "ax.set_frame_on(False)\n",
    "img = np.ones((6, 6))\n",
    "clf = ViolaJonesClassifier(10, 5)\n",
    "integral_img = clf.to_integral_img(img)\n",
    "print(integral_img)\n",
    "print(feat.apply_feature(integral_img))\n",
    "if feat.is_valid():\n",
    "    print(\"Its a valid feature\")\n",
    "else:\n",
    "    print(\"Invalid feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd89a5a655f4f1da1899906682d62b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-95cb29cfad19>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f19f6e412b7b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, features)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a214dfd4bec1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, features)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a214dfd4bec1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, depth, max_depth)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_top_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_bottom_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mloss_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_top_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a214dfd4bec1>\u001b[0m in \u001b[0;36mfind_c\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mones\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2228\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2229\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = ViolaJonesClassifier(num_trees=10, max_depth=1)\n",
    "clf.fit(X_train[:20], y_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like np.unique, but array [0, 0, 0, 1] will result in [2, 3] instead of [0, 3]\n",
    "def get_unique_indices(arr):\n",
    "    idx = []\n",
    "    last = None\n",
    "    for el in arr:\n",
    "        if el == last:\n",
    "    \n",
    "\n",
    "\n",
    "a = np.array([1, 1, 1, 5, 7])\n",
    "\n",
    "un, index = np.unique(a, return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ensembles.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
