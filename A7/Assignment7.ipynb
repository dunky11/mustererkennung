{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo9GWxKgTN1h"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax8ea49_bkdb"
   },
   "source": [
    "### Load the spam dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.347720Z",
     "start_time": "2018-11-29T11:28:47.572823Z"
    },
    "id": "V7XaSv5wTN1i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.data import lfw_subset\n",
    "from sklearn.datasets import fetch_openml\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.406520Z",
     "start_time": "2018-11-29T11:28:48.349530Z"
    },
    "id": "sT2Hk2k-TN1i"
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('spambase.data', header=None))\n",
    "\n",
    "X = data[:,:-1] # features\n",
    "y = data[:,-1] # Last column is label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def gini(y_true, c):\n",
    "    \"\"\"\n",
    "    For simplicity reasons this assumes that there are only 2 classes\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    p_mk = np.mean(y_true == c)\n",
    "\n",
    "    return 2 * p_mk * (1 - p_mk)\n",
    "\n",
    "class LeafNode():\n",
    "    def fit(self, c):\n",
    "        self.c = c\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.c\n",
    "    \n",
    "class InternalNode():\n",
    "    \"\"\"\n",
    "    Node of decision tree, which accepts tabular data\n",
    "    \"\"\"\n",
    "    def fit(self, x, y, depth, max_depth):\n",
    "        m, n = x.shape\n",
    "        # columns are j, split_index, loss_total\n",
    "        split_infos = []\n",
    "            \n",
    "        for j in range(n):\n",
    "            # sort rows by feature j in ascending order\n",
    "            sorted_indices = x[:,j].argsort()\n",
    "            x, y = x[sorted_indices], y[sorted_indices]\n",
    "            for split_index in self.get_unique_indices(x[:, j])[:-1]:\n",
    "                y_top_split = y[:split_index + 1]\n",
    "                y_bottom_split = y[split_index + 1:]\n",
    "                \n",
    "                if y_top_split.shape[0] == 0:\n",
    "                    raise Exception(\"Error 1\")\n",
    "                    \n",
    "                if y_bottom_split.shape[0] == 0:\n",
    "                    raise Exception(\"Error 2\")\n",
    "                \n",
    "                c1 = self.find_c(y_top_split)\n",
    "                c2 = self.find_c(y_bottom_split)\n",
    "                \n",
    "                loss_1 = gini(y_top_split, c1)\n",
    "                loss_2 = gini(y_bottom_split, c2)\n",
    "                \n",
    "                # use weighted average which had better results\n",
    "                loss_total = (y_top_split.shape[0] / m) * loss_1  + (y_bottom_split.shape[0] / m) * loss_2\n",
    "                \n",
    "                row = np.array([j, split_index, loss_total])\n",
    "                split_infos.append(row)\n",
    "                \n",
    "        split_infos = np.array(split_infos)\n",
    "        best_split_idx = np.argmin(split_infos[:,-1], axis=0)\n",
    "        best_split = split_infos[best_split_idx]\n",
    "        self.j = int(best_split[0])\n",
    "        split_index = int(best_split[1])\n",
    "        \n",
    "        sorted_indices = x[:,j].argsort()\n",
    "        x, y = x[sorted_indices], y[sorted_indices]\n",
    "        \n",
    "        x_top_split, y_top_split = x[:split_index + 1], y[:split_index + 1]\n",
    "        x_bottom_split, y_bottom_split = x[split_index + 1:], y[split_index + 1:]\n",
    "        \n",
    "        self.z = (x_top_split[-1, self.j] + x_bottom_split[0, self.j]) / 2\n",
    "        \n",
    "        if self.is_pure(y_top_split) or x_top_split.shape[0] <= 2 or depth >= max_depth:\n",
    "            self.left_child = LeafNode()\n",
    "            c = self.find_c(y_top_split)\n",
    "            self.left_child.fit(c)\n",
    "        else:\n",
    "            self.left_child = InternalNode()\n",
    "            self.left_child.fit(x_top_split, y_top_split, depth + 1, max_depth)\n",
    "            \n",
    "        if self.is_pure(y_bottom_split) or x_bottom_split.shape[0] <= 2 or depth >= max_depth:\n",
    "            self.right_child = LeafNode()\n",
    "            c = self.find_c(y_bottom_split)\n",
    "            self.right_child.fit(c)\n",
    "        else:\n",
    "            self.right_child = InternalNode()\n",
    "            self.right_child.fit(x_bottom_split, y_bottom_split, depth + 1, max_depth)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if x[self.j] <= self.z:\n",
    "            return self.left_child.predict(x)\n",
    "        return self.right_child.predict(x)\n",
    "    \n",
    "    def get_unique_indices(self, arr):\n",
    "        idx = []\n",
    "        arr_len = len(arr)\n",
    "        for i in range(len(arr)):\n",
    "            if i == arr_len - 1:\n",
    "                idx.append(i)\n",
    "            elif arr[i] != arr[i + 1]:\n",
    "                idx.append(i)\n",
    "        return idx\n",
    "    \n",
    "    def find_c(self, y):\n",
    "        \"\"\"\n",
    "        For simplicity reasons this assumes that there are only 2 classes\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        zeros = np.sum(y == 0)\n",
    "        ones = np.sum(y == 1)\n",
    "        if ones > zeros:\n",
    "            return 1\n",
    "        return 0\n",
    "        \n",
    "    def is_pure(self, y):\n",
    "        y = np.array(y)\n",
    "        if np.sum(y == 0) == y.shape[0] or np.sum(y == 1) == y.shape[0]:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "class DecisionTreeClassifier():\n",
    "    \"\"\"\n",
    "    Basically just holds the root node of the tree which starts the recursion\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def fit(self, x, y, features):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        self.root = InternalNode()\n",
    "        self.root.fit(x, y, 1, self.max_depth)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_preds = []\n",
    "        for sample in x:\n",
    "            y_pred = self.root.predict(sample)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Delete later\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class AdaBoost():\n",
    "    def __init__(self, num_trees, max_depth):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "            \n",
    "    def fit(self, x, y, features=None):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        self.trees = []\n",
    "        self.says = []\n",
    "        for i in tqdm(range(self.num_trees)):\n",
    "            # sample weights will always add up to one\n",
    "            sample_weights = np.ones((y.shape[0], )) / y.shape[0]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(x, y, features)\n",
    "            y_pred = tree.predict(x)\n",
    "            error = self.calculate_error(y, y_pred, sample_weights)\n",
    "            say = self.error_to_say(error)\n",
    "            sample_weights = self.update_sample_weights(y, y_pred, say, sample_weights)\n",
    "            x, y = self.weighted_dataset(x, y, sample_weights)\n",
    "            self.trees.append(tree)\n",
    "            self.says.append(say)\n",
    "            \n",
    "        self.says = np.array(self.says)\n",
    "            \n",
    "    def weighted_dataset(self, x, y, sample_weights):\n",
    "        x_new, y_new = [], []\n",
    "        sample_weights_cum = np.cumsum(sample_weights)\n",
    "        rand = np.random.uniform(low=0.0, high=1.0, size=(x.shape[0], ))\n",
    "        for rand_el in rand:\n",
    "            for i, cum_weight in enumerate(sample_weights_cum):\n",
    "                if cum_weight >= rand_el:\n",
    "                    x_new.append(x[i])\n",
    "                    y_new.append(y[i])\n",
    "                    break\n",
    "        return np.array(x_new), np.array(y_new)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def calculate_error(self, y_true, y_pred, sample_weights):\n",
    "        \"\"\"\n",
    "        How much say a stump has is calculated by it's error, which is just the\n",
    "        sum of the sample_weights for the missclassified samples.\n",
    "        The error is always between 0 and 1 because the sample weights add up to one.\n",
    "        0 is the lowest possible error and 1 is the highest.\n",
    "        \"\"\"\n",
    "        error_idx = y_true != y_pred\n",
    "        return np.sum(sample_weights[error_idx])\n",
    "    \n",
    "    def error_to_say(self, error):\n",
    "        \"\"\"\n",
    "        Transforms the error a stump has into it's say which will be used\n",
    "        to weight the importance of one stumps prediction in the final prediction.\n",
    "        The say is ~ between 3.5 and -3.5 which means a stumps prediction can actually\n",
    "        be weighted negaively in the final prediction if it error is high.\n",
    "        If error is 0 we will have division by 0, if error is 1, we will have log(0)\n",
    "        which is also not possible. So a small eps is added / subtracted from the \n",
    "        error to keep calculations stable.\n",
    "        \"\"\"\n",
    "        eps = 10 ** -10\n",
    "        if error == 0:\n",
    "            error = error + eps\n",
    "        elif error == 1:\n",
    "            error = error - eps\n",
    "        return 0.5 * np.log((1 - error) / error)\n",
    "    \n",
    "    def update_sample_weights(self, y_true, y_pred, say, sample_weights):\n",
    "        \"\"\"\n",
    "        Updates the sample weights by scaling them based on the amount of say the stump\n",
    "        has and wether it properly classified the sample.\n",
    "        If say is high and the sample was missclassified, the sample weight will go up.\n",
    "        If say is high and the sample was propely classified, the sample weight will go down.\n",
    "        If say is low and the sample was missclassified, the sample weight will go down.\n",
    "        If say is low and the sample was properly classified, the sample weight will go up.\n",
    "        After updating the sample weights will still sum up to one.\n",
    "        \"\"\"\n",
    "        sample_weights = np.where(y_true == y_pred, \n",
    "                                  sample_weights * np.exp(-say), \n",
    "                                  sample_weights * np.exp(say))\n",
    "        # normalization so sample_weights add up to 1 again\n",
    "        sample_weights = sample_weights / np.sum(sample_weights)\n",
    "        return sample_weights\n",
    "        \n",
    "    def predict(self, x, use_cascade=False):\n",
    "        y_preds = []\n",
    "        for sample in x:\n",
    "            votes = []\n",
    "            for tree in self.trees:\n",
    "                # decision tree expects matrix as input\n",
    "                sample = sample.reshape((1, -1))\n",
    "                prediction = tree.predict(sample)\n",
    "                if use_cascade and prediction[0] == 0:\n",
    "                    y_preds.append(0)\n",
    "                    break\n",
    "                votes.append(prediction)\n",
    "            votes = np.array(votes).reshape((-1, ))\n",
    "            yes_say = np.sum(self.says[votes == 1])\n",
    "            no_say = np.sum(self.says[votes == 0])\n",
    "            if yes_say > no_say:\n",
    "                y_preds.append(1)\n",
    "            else:\n",
    "                y_preds.append(0)\n",
    "                        \n",
    "        return np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044a60116b004199b19004d75429abd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 27.1 s, sys: 83.5 ms, total: 27.2 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoost(num_trees=20, max_depth=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889661164205039\n",
      "CPU times: user 97 ms, sys: 50 µs, total: 97.1 ms\n",
      "Wall time: 95.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to AdaBoost with depth of 2 instead of 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee2f110c2bf4ae1b35c8052cf657e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 37.1 s, sys: 38.9 ms, total: 37.1 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoost(num_trees=20, max_depth=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89748045178106\n",
      "CPU times: user 107 ms, sys: 71 µs, total: 107 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Viola-Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    \"\"\"\n",
    "    Generates dataset of 250 images of faces with labels 1 and 250 images of digits with label 0, \n",
    "    each are 25x25 pixels.\n",
    "    \"\"\"\n",
    "    face_data = lfw_subset()\n",
    "    noise_data = np.random.uniform(size=face_data.shape)\n",
    "    face_labels = np.ones((face_data.shape[0], ))\n",
    "    noise_labels = np.zeros((noise_data.shape[0], ))\n",
    "    x = np.vstack((face_data, noise_data))\n",
    "    y = np.hstack((face_labels, noise_labels))\n",
    "    assert(x.shape[0] == y.shape[0])\n",
    "    return x, y\n",
    "\n",
    "x, y = generate_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectBase():\n",
    "    def calculate_area(self, integral_img,  ul_pixel_cord, lr_pixel_cord):\n",
    "        \"\"\" Calculates the of the integral_img given by two pixel coordinates.\n",
    "        ul_pixel_cord should be outside of the calculated area.\n",
    "        lr_pixel_cord is inside of the calculated area.\n",
    "        \"\"\"\n",
    "        if ul_pixel_cord[0] < 0 or ul_pixel_cord[1] < 0:\n",
    "            A = 0\n",
    "        else:\n",
    "            A = integral_img[ul_pixel_cord[0], ul_pixel_cord[1]]\n",
    "            \n",
    "        if ul_pixel_cord[0] < 0:\n",
    "            B = 0\n",
    "        else:\n",
    "            B = integral_img[ul_pixel_cord[0], lr_pixel_cord[1]]\n",
    "            \n",
    "        if ul_pixel_cord[1] < 0:\n",
    "            C = 0\n",
    "        else:\n",
    "            C = integral_img[ul_pixel_cord[1], lr_pixel_cord[0]]\n",
    "            \n",
    "        D = integral_img[lr_pixel_cord[0], lr_pixel_cord[1]]\n",
    "        return A - B - C + D\n",
    "\n",
    "\n",
    "class TwoRect(RectBase):\n",
    "    \"\"\" Feature for Viola-Jones, which looks like:\n",
    "    -----\n",
    "    --B--\n",
    "    --W--\n",
    "    -----\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, scale_x, scale_y, img_shape):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.scale_x = scale_x\n",
    "        self.scale_y = scale_y\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def is_valid(self):\n",
    "        \"\"\"\n",
    "        Returns wether the feature fits on the image\n",
    "        \"\"\"\n",
    "        lowest_pixel = self.x + (self.scale_x * 2) - 1\n",
    "        if lowest_pixel > self.img_shape[0] - 1:\n",
    "            return False\n",
    "        most_right_pixel = self.y + self.scale_y - 1\n",
    "        if most_right_pixel > self.img_shape[1] - 1:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_pixel_cords(self):\n",
    "        black_area_ul = [self.x - 1, self.y - 1]\n",
    "        black_area_lr = [self.x + self.scale_x - 1, self.y + self.scale_y - 1]\n",
    "        white_area_ul = [self.x + self.scale_x - 1, self.y - 1]\n",
    "        white_area_lr = [self.x + (self.scale_x * 2) - 1, self.y + self.scale_y - 1]\n",
    "        return {\n",
    "            \"black_area_ul\": black_area_ul,\n",
    "            \"black_area_lr\": black_area_lr,\n",
    "            \"white_area_ul\": white_area_ul,\n",
    "            \"white_area_lr\": white_area_lr\n",
    "        }\n",
    "    \n",
    "    def apply_feature(self, integral_img):\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        black_area_sum = self.calculate_area(integral_img, pixel_cords[\"black_area_ul\"], \n",
    "                                             pixel_cords[\"black_area_lr\"])\n",
    "        white_area_sum = self.calculate_area(integral_img, pixel_cords[\"white_area_ul\"], \n",
    "                                             pixel_cords[\"white_area_lr\"])\n",
    "        return white_area_sum - black_area_sum\n",
    "    \n",
    "    def visualise_feature(self):\n",
    "        img = np.ones((self.img_shape[0], self.img_shape[1])) * 0.5\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        for x in range(pixel_cords[\"black_area_ul\"][0] + 1, pixel_cords[\"black_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"black_area_ul\"][1] + 1, pixel_cords[\"black_area_lr\"][1] + 1):\n",
    "                img[x, y] = 0\n",
    "        for x in range(pixel_cords[\"white_area_ul\"][0] + 1, pixel_cords[\"white_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"white_area_ul\"][1] + 1, pixel_cords[\"white_area_lr\"][1] + 1):\n",
    "                img[x, y] = 1\n",
    "        return img\n",
    "\n",
    "class ThreeRect(RectBase):\n",
    "    \"\"\" Feature for Viola-Jones, which looks like:\n",
    "    -----\n",
    "    -BWB-\n",
    "    -----\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, scale_x, scale_y, img_shape):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.scale_x = scale_x\n",
    "        self.scale_y = scale_y\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def is_valid(self):\n",
    "        \"\"\"\n",
    "        Returns wether the feature fits on the image\n",
    "        \"\"\"\n",
    "        lowest_pixel = self.x + self.scale_x - 1\n",
    "        if lowest_pixel > self.img_shape[0] - 1:\n",
    "            return False\n",
    "        most_right_pixel = self.y + (self.scale_y * 3) - 1\n",
    "        if most_right_pixel > self.img_shape[1] - 1:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_pixel_cords(self):\n",
    "        left_black_area_ul = [self.x - 1, self.y - 1]\n",
    "        left_black_area_lr = [self.x + self.scale_x - 1, self.y + self.scale_y - 1]\n",
    "        white_area_ul = [self.x - 1, self.y + self.scale_y - 1]\n",
    "        white_area_lr = [self.x + self.scale_x - 1, self.y + self.scale_y * 2 - 1]\n",
    "        right_black_area_ul = [self.x - 1, self.y + self.scale_y * 2 - 1]\n",
    "        right_black_area_lr = [self.x + self.scale_x - 1, self.y + (self.scale_y * 3) - 1]\n",
    "        return {\n",
    "            \"left_black_area_ul\": left_black_area_ul,\n",
    "            \"left_black_area_lr\": left_black_area_lr,\n",
    "            \"white_area_ul\": white_area_ul,\n",
    "            \"white_area_lr\": white_area_lr, \n",
    "            \"right_black_area_ul\": right_black_area_ul,\n",
    "            \"right_black_area_lr\": right_black_area_lr\n",
    "        }\n",
    "    \n",
    "    def apply_feature(self, integral_img):\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        left_black_area_sum = self.calculate_area(integral_img, pixel_cords[\"left_black_area_ul\"], \n",
    "                                             pixel_cords[\"left_black_area_lr\"])\n",
    "        white_area_sum = self.calculate_area(integral_img, pixel_cords[\"white_area_ul\"], \n",
    "                                             pixel_cords[\"white_area_lr\"])\n",
    "        right_black_area_sum = self.calculate_area(integral_img, pixel_cords[\"right_black_area_ul\"], \n",
    "                                             pixel_cords[\"right_black_area_lr\"])\n",
    "        return white_area_sum - (left_black_area_sum + right_black_area_sum)\n",
    "    \n",
    "    def visualise_feature(self):\n",
    "        img = np.ones((self.img_shape[0], self.img_shape[1])) * 0.5\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        for x in range(pixel_cords[\"left_black_area_ul\"][0] + 1, pixel_cords[\"left_black_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"left_black_area_ul\"][1] + 1, pixel_cords[\"left_black_area_lr\"][1] + 1):\n",
    "                img[x, y] = 0\n",
    "        for x in range(pixel_cords[\"white_area_ul\"][0] + 1, pixel_cords[\"white_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"white_area_ul\"][1] + 1, pixel_cords[\"white_area_lr\"][1] + 1):\n",
    "                img[x, y] = 1\n",
    "        for x in range(pixel_cords[\"right_black_area_ul\"][0] + 1, pixel_cords[\"right_black_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"right_black_area_ul\"][1] + 1, pixel_cords[\"right_black_area_lr\"][1] + 1):\n",
    "                img[x, y] = 0\n",
    "        return img\n",
    "    \n",
    "class FourRect(RectBase):\n",
    "    \"\"\" Feature for Viola-Jones, which looks like:\n",
    "    ------\n",
    "    --WB--\n",
    "    --BW--\n",
    "    ------\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, scale_x, scale_y, img_shape):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.scale_x = scale_x\n",
    "        self.scale_y = scale_y\n",
    "        self.img_shape = img_shape\n",
    "    \n",
    "    def is_valid(self):\n",
    "        \"\"\"\n",
    "        Returns wether the feature fits on the image\n",
    "        \"\"\"\n",
    "        lowest_pixel = self.x + self.scale_x * 2 - 1\n",
    "        if lowest_pixel > self.img_shape[0] - 1:\n",
    "            return False\n",
    "        most_right_pixel = self.y + self.scale_y * 2 - 1\n",
    "        if most_right_pixel > self.img_shape[1] - 1:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def get_pixel_cords(self):\n",
    "        left_white_area_ul = [self.x - 1, self.y - 1]\n",
    "        left_white_area_lr = [self.x + self.scale_x - 1, self.y + self.scale_y - 1]\n",
    "        left_black_area_ul = [self.x + self.scale_x - 1, self.y - 1]\n",
    "        left_black_area_lr = [self.x + self.scale_x * 2 - 1, self.y + self.scale_y - 1]\n",
    "        right_black_area_ul = [self.x - 1, self.y + self.scale_y - 1]\n",
    "        right_black_area_lr = [self.x + self.scale_x - 1, self.y + self.scale_y * 2 - 1]\n",
    "        right_white_area_ul = [self.x + self.scale_x - 1, self.y + self.scale_y - 1]\n",
    "        right_white_area_lr = [self.x + self.scale_x * 2 - 1, self.y + self.scale_y * 2 - 1]\n",
    "        return {\n",
    "            \"left_white_area_ul\": left_white_area_ul,\n",
    "            \"left_white_area_lr\": left_white_area_lr,\n",
    "            \"left_black_area_ul\": left_black_area_ul,\n",
    "            \"left_black_area_lr\": left_black_area_lr,\n",
    "            \"right_black_area_ul\": right_black_area_ul,\n",
    "            \"right_black_area_lr\": right_black_area_lr,\n",
    "            \"right_white_area_ul\": right_white_area_ul,\n",
    "            \"right_white_area_lr\": right_white_area_lr\n",
    "        }\n",
    "    \n",
    "    def apply_feature(self, integral_img):\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        left_white_area_sum = self.calculate_area(integral_img, pixel_cords[\"left_white_area_ul\"], \n",
    "                                             pixel_cords[\"left_white_area_lr\"])\n",
    "        left_black_area_sum = self.calculate_area(integral_img, pixel_cords[\"left_black_area_ul\"], \n",
    "                                             pixel_cords[\"left_black_area_lr\"])\n",
    "        right_black_area_sum = self.calculate_area(integral_img, pixel_cords[\"right_black_area_ul\"], \n",
    "                                             pixel_cords[\"right_black_area_lr\"])\n",
    "        right_white_area_sum = self.calculate_area(integral_img, pixel_cords[\"right_white_area_ul\"], \n",
    "                                             pixel_cords[\"right_white_area_lr\"])\n",
    "        return left_white_area_sum - left_black_area_sum - right_black_area_sum + right_white_area_sum\n",
    "    \n",
    "    def visualise_feature(self):\n",
    "        img = np.ones((self.img_shape[0], self.img_shape[1])) * 0.5\n",
    "        pixel_cords = self.get_pixel_cords()\n",
    "        for x in range(pixel_cords[\"left_white_area_ul\"][0] + 1, pixel_cords[\"left_white_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"left_white_area_ul\"][1] + 1, pixel_cords[\"left_white_area_lr\"][1] + 1):\n",
    "                img[x, y] = 1\n",
    "        for x in range(pixel_cords[\"left_black_area_ul\"][0] + 1, pixel_cords[\"left_black_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"left_black_area_ul\"][1] + 1, pixel_cords[\"left_black_area_lr\"][1] + 1):\n",
    "                img[x, y] = 0\n",
    "        for x in range(pixel_cords[\"right_black_area_ul\"][0] + 1, pixel_cords[\"right_black_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"right_black_area_ul\"][1] + 1, pixel_cords[\"right_black_area_lr\"][1] + 1):\n",
    "                img[x, y] = 0\n",
    "        for x in range(pixel_cords[\"right_white_area_ul\"][0] + 1, pixel_cords[\"right_white_area_lr\"][0] + 1):\n",
    "            for y  in range(pixel_cords[\"right_white_area_ul\"][1] + 1, pixel_cords[\"right_white_area_lr\"][1] + 1):\n",
    "                img[x, y] = 1\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolaJonesClassifier():\n",
    "    def __init__(self, num_trees, max_depth, max_features=None):\n",
    "        self.adaboost = AdaBoost(num_trees, max_depth)\n",
    "        self.max_features = max_features\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        features = self.generate_features(x[0].shape)\n",
    "        if self.max_features != None:\n",
    "            random.shuffle(features)\n",
    "            features = features[:self.max_features]\n",
    "        x = self.transform_x(x, features)\n",
    "        self.adaboost.fit(x, y)\n",
    "        self.features = features\n",
    "        \n",
    "    def predict(self, x, use_cascade=False):\n",
    "        x = np.copy(x)\n",
    "        x = self.transform_x(x, self.features)\n",
    "        return self.adaboost.predict(x, use_cascade)\n",
    "    \n",
    "    def transform_x(self, x, features):\n",
    "        imgs = []\n",
    "        for sample in x:\n",
    "            imgs.append(self.to_integral_img(sample))\n",
    "        x = np.array(imgs)\n",
    "        x = self.apply_features(x, features)\n",
    "        return x\n",
    "    \n",
    "    def apply_features(self, integral_imgs, features):\n",
    "        \"\"\"\n",
    "        Transforms the integral images into a tabular dataset of shape (num_imgs, num_features),\n",
    "        where [i, j] corresponds to the j-th feature applied to the i-th img\n",
    "        \"\"\"\n",
    "        x_new = np.zeros((integral_imgs.shape[0], len(features)))\n",
    "        for row in range(x_new.shape[0]):\n",
    "            for feature in range(len(features)):\n",
    "                x_new[row, feature] = features[feature].apply_feature(integral_imgs[row])\n",
    "        return x_new\n",
    "    \n",
    "    def to_integral_img(self, img):\n",
    "        img = img.copy()\n",
    "        for row in range(img.shape[0]):\n",
    "            for col in range(img.shape[1]):\n",
    "                new_val = img[row, col]\n",
    "                if row != 0:\n",
    "                    new_val += img[row - 1, col]\n",
    "                if col != 0:\n",
    "                    new_val += img[row, col - 1]\n",
    "                if row != 0 and col != 0:\n",
    "                    new_val -= img[row - 1, col - 1]\n",
    "                img[row, col] = new_val\n",
    "        return img\n",
    "    \n",
    "    def generate_features(self, img_shape):\n",
    "        features = []\n",
    "        for x in range(img_shape[0]):\n",
    "            for y in range(img_shape[1]):\n",
    "                for scale_x in range(1, img_shape[0]):\n",
    "                    for scale_y in range(1, img_shape[1]):\n",
    "                        feat = TwoRect(x, y, scale_x, scale_y, img_shape)\n",
    "                        if feat.is_valid():\n",
    "                            features.append(feat)\n",
    "                        feat = ThreeRect(x, y, scale_x, scale_y, img_shape)\n",
    "                        if feat.is_valid():\n",
    "                            features.append(feat)\n",
    "                        feat = FourRect(x, y, scale_x, scale_y, img_shape)\n",
    "                        if feat.is_valid():\n",
    "                            features.append(feat)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6719295726df4ebab326d633a83f5443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 4min 2s, sys: 819 ms, total: 4min 2s\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = ViolaJonesClassifier(num_trees=10, max_depth=1, max_features=3000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n",
      "CPU times: user 1.82 s, sys: 22 µs, total: 1.82 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the 10 most important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = clf.adaboost.trees[:10]\n",
    "features = clf.features\n",
    "most_imp_features = [features[tree.root.j] for tree in trees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(16, 16))\n",
    "columns = 2\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    visualization = most_imp_features[i - 1].visualise_feature()\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(visualization, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running AdaBoost using cascade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-78ed4e2ac881>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, use_cascade)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cascade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d0434587dcd6>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, use_cascade)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mvotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mvotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0myes_say\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvotes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mno_say\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvotes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0myes_say\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mno_say\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 10 but corresponding boolean dimension is 4"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test, use_cascade=True)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ensembles.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
