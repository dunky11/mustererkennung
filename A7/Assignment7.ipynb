{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo9GWxKgTN1h"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.347720Z",
     "start_time": "2018-11-29T11:28:47.572823Z"
    },
    "id": "V7XaSv5wTN1i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax8ea49_bkdb"
   },
   "source": [
    "### Load the spam dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.406520Z",
     "start_time": "2018-11-29T11:28:48.349530Z"
    },
    "id": "sT2Hk2k-TN1i"
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('spambase.data', header=None))\n",
    "\n",
    "X = data[:,:-1] # features\n",
    "y = data[:,-1] # Last column is label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def gini(y_true, c):\n",
    "    \"\"\"\n",
    "    For simplicity reasons this assumes that there are only 2 classes\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    p_mk = np.mean(y_true == c)\n",
    "\n",
    "    return 2 * p_mk * (1 - p_mk)\n",
    "\n",
    "class LeafNode():\n",
    "    def fit(self, c):\n",
    "        self.c = c\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.c\n",
    "    \n",
    "class InternalNode():\n",
    "    def fit(self, x, y, depth, max_depth, max_features_to_sample):\n",
    "        m, n = x.shape\n",
    "        # columns are j, split_index, loss_total\n",
    "        split_infos = []\n",
    "        if max_features_to_sample == None:\n",
    "            iter_over = range(n)\n",
    "        else:\n",
    "            # in RandomForest we build the tree only on a subset of the features at each Node\n",
    "            iter_over = np.random.permutation(n)[:max_features_to_sample]\n",
    "            \n",
    "        for j in iter_over:\n",
    "            # sort rows by feature j in ascending order\n",
    "            sorted_indices = x[:,j].argsort()\n",
    "            x, y = x[sorted_indices], y[sorted_indices]\n",
    "            for split_index in range(0, m - 1):\n",
    "                \n",
    "                y_top_split = y[:split_index + 1]\n",
    "                y_bottom_split = y[split_index + 1:]\n",
    "                \n",
    "                if y_top_split.shape[0] == 0:\n",
    "                    raise Exception(\"Error 1\")\n",
    "                    \n",
    "                if y_bottom_split.shape[0] == 0:\n",
    "                    raise Exception(\"Error 2\")\n",
    "                \n",
    "                c1 = self.find_c(y_top_split)\n",
    "                c2 = self.find_c(y_bottom_split)\n",
    "                \n",
    "                loss_1 = gini(y_top_split, c1)\n",
    "                loss_2 = gini(y_bottom_split, c2)\n",
    "                \n",
    "                # use weighted average which had better results\n",
    "                loss_total = (y_top_split.shape[0] / m) * loss_1  + (y_bottom_split.shape[0] / m) * loss_2\n",
    "                \n",
    "                row = np.array([j, split_index, loss_total])\n",
    "                split_infos.append(row)\n",
    "                \n",
    "        split_infos = np.array(split_infos)\n",
    "        best_split_idx = np.argmin(split_infos[:,-1], axis=0)\n",
    "        best_split = split_infos[best_split_idx]\n",
    "        self.j = int(best_split[0])\n",
    "        split_index = int(best_split[1])\n",
    "        \n",
    "        sorted_indices = x[:,j].argsort()\n",
    "        x, y = x[sorted_indices], y[sorted_indices]\n",
    "        \n",
    "        x_top_split, y_top_split = x[:split_index + 1], y[:split_index + 1]\n",
    "        x_bottom_split, y_bottom_split = x[split_index + 1:], y[split_index + 1:]\n",
    "        \n",
    "        self.z = (x_top_split[-1, self.j] + x_bottom_split[0, self.j]) / 2\n",
    "        \n",
    "        if self.is_pure(y_top_split) or x_top_split.shape[0] <= 2 or depth >= max_depth:\n",
    "            self.left_child = LeafNode()\n",
    "            c = self.find_c(y_top_split)\n",
    "            self.left_child.fit(c)\n",
    "        else:\n",
    "            self.left_child = InternalNode()\n",
    "            self.left_child.fit(x_top_split, y_top_split, depth + 1, max_depth, max_features_to_sample)\n",
    "            \n",
    "        if self.is_pure(y_bottom_split) or x_bottom_split.shape[0] <= 2 or depth >= max_depth:\n",
    "            self.right_child = LeafNode()\n",
    "            c = self.find_c(y_bottom_split)\n",
    "            self.right_child.fit(c)\n",
    "        else:\n",
    "            self.right_child = InternalNode()\n",
    "            self.right_child.fit(x_bottom_split, y_bottom_split, depth + 1, max_depth, max_features_to_sample)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if x[self.j] <= self.z:\n",
    "            return self.left_child.predict(x)\n",
    "        return self.right_child.predict(x)\n",
    "    \n",
    "    def find_c(self, y):\n",
    "        \"\"\"\n",
    "        For simplicity reasons this assumes that there are only 2 classes\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        zeros = np.sum(y == 0)\n",
    "        ones = np.sum(y == 1)\n",
    "        if ones > zeros:\n",
    "            return 1\n",
    "        return 0\n",
    "        \n",
    "    def is_pure(self, y):\n",
    "        y = np.array(y)\n",
    "        if np.sum(y == 0) == y.shape[0] or np.sum(y == 1) == y.shape[0]:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "class DecisionTreeClassifier():\n",
    "    \"\"\"\n",
    "    Basically just holds the root node of the tree which starts the recursion\n",
    "    features_to_sample will be set when creating a RandomForest \n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth, features_to_sample=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.features_to_sample = features_to_sample\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        self.root = InternalNode()\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        self.root.fit(x, y, 1, self.max_depth, self.features_to_sample)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_preds = []\n",
    "        for sample in x:\n",
    "            y_pred = self.root.predict(sample)\n",
    "            y_preds.append(y_pred)\n",
    "        return np.array(y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Delete later\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class AdaBoost():\n",
    "    def __init__(self, num_trees, max_depth):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "            \n",
    "    def fit(self, x, y):\n",
    "        x = np.copy(x)\n",
    "        y = np.copy(y)\n",
    "        self.trees = []\n",
    "        self.says = []\n",
    "        for i in tqdm(range(self.num_trees)):\n",
    "            # sample weights will always add up to one\n",
    "            sample_weights = np.ones((y.shape[0], )) / y.shape[0]\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(x, y)\n",
    "            y_pred = tree.predict(x)\n",
    "            error = self.calculate_error(y, y_pred, sample_weights)\n",
    "            say = self.error_to_say(error)\n",
    "            sample_weights = self.update_sample_weights(y, y_pred, say, sample_weights)\n",
    "            x, y = self.weighted_dataset(x, y, sample_weights)\n",
    "            self.trees.append(tree)\n",
    "            self.says.append(say)\n",
    "            \n",
    "        self.says = np.array(self.says)\n",
    "            \n",
    "    def weighted_dataset(self, x, y, sample_weights):\n",
    "        x_new, y_new = [], []\n",
    "        sample_weights_cum = np.cumsum(sample_weights)\n",
    "        rand = np.random.uniform(low=0.0, high=1.0, size=(x.shape[0], ))\n",
    "        for rand_el in rand:\n",
    "            for i, cum_weight in enumerate(sample_weights_cum):\n",
    "                if cum_weight >= rand_el:\n",
    "                    x_new.append(x[i])\n",
    "                    y_new.append(y[i])\n",
    "                    break\n",
    "        return np.array(x_new), np.array(y_new)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def calculate_error(self, y_true, y_pred, sample_weights):\n",
    "        \"\"\"\n",
    "        How much say a stump has is calculated by it's error, which is just the\n",
    "        sum of the sample_weights for the missclassified samples.\n",
    "        The error is always between 0 and 1 because the sample weights add up to one.\n",
    "        0 is the lowest possible error and 1 is the highest.\n",
    "        \"\"\"\n",
    "        error_idx = y_true != y_pred\n",
    "        return np.sum(sample_weights[error_idx])\n",
    "    \n",
    "    def error_to_say(self, error):\n",
    "        \"\"\"\n",
    "        Transforms the error a stump has into it's say which will be used\n",
    "        to weight the importance of one stumps prediction in the final prediction.\n",
    "        The say is ~ between 3.5 and -3.5 which means a stumps prediction can actually\n",
    "        be weighted negaively in the final prediction if it error is high.\n",
    "        If error is 0 we will have division by 0, if error is 1, we will have log(0)\n",
    "        which is also not possible. So a small eps is added / subtracted from the \n",
    "        error to keep calculations stable.\n",
    "        \"\"\"\n",
    "        eps = 10 ** -10\n",
    "        if error == 0:\n",
    "            error = error + eps\n",
    "        elif error == 1:\n",
    "            error = error - eps\n",
    "        return 0.5 * np.log((1 - error) / error)\n",
    "    \n",
    "    def update_sample_weights(self, y_true, y_pred, say, sample_weights):\n",
    "        \"\"\"\n",
    "        Updates the sample weights by scaling them based on the amount of say the stump\n",
    "        has and wether it properly classified the sample.\n",
    "        If say is high and the sample was missclassified, the sample weight will go up.\n",
    "        If say is high and the sample was propely classified, the sample weight will go down.\n",
    "        If say is low and the sample was missclassified, the sample weight will go down.\n",
    "        If say is low and the sample was properly classified, the sample weight will go up.\n",
    "        After updating the sample weights will still sum up to one.\n",
    "        \"\"\"\n",
    "        sample_weights = np.where(y_true == y_pred, \n",
    "                                  sample_weights * np.exp(-say), \n",
    "                                  sample_weights * np.exp(say))\n",
    "        # normalization so sample_weights add up to 1 again\n",
    "        sample_weights = sample_weights / np.sum(sample_weights)\n",
    "        return sample_weights\n",
    "        \n",
    "    def predict(self, x):\n",
    "        y_preds = []\n",
    "        for sample in x:\n",
    "            votes = []\n",
    "            for tree in self.trees:\n",
    "                # decision tree expects matrix as input\n",
    "                sample = sample.reshape((1, -1))\n",
    "                votes.append(tree.predict(sample))\n",
    "            votes = np.array(votes).reshape((-1, ))\n",
    "            yes_say = np.sum(self.says[votes == 1])\n",
    "            no_say = np.sum(self.says[votes == 0])\n",
    "            if yes_say > no_say:\n",
    "                y_preds.append(1)\n",
    "            else:\n",
    "                y_preds.append(0)\n",
    "        return np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4130fb3deae42b8b392b4255d7d755b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 38.8 s, sys: 83.7 ms, total: 38.9 s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoost(num_trees=10, max_depth=1)\n",
    "clf.fit(X_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8609904430929627\n",
      "CPU times: user 70.6 ms, sys: 0 ns, total: 70.6 ms\n",
      "Wall time: 69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to AdaBoost with depth of 2 instead of 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7abcb0a19940e9b8cbf63f61478637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min 15s, sys: 135 ms, total: 1min 16s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = AdaBoost(num_trees=10, max_depth=2)\n",
    "clf.fit(X_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.889661164205039\n",
      "CPU times: user 66.7 ms, sys: 0 ns, total: 66.7 ms\n",
      "Wall time: 65.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Viola-Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_integral_img(img):\n",
    "    img = img.copy()\n",
    "    for row in range(img.shape[0]):\n",
    "        for col in range(img.shape[1]):\n",
    "            new_val = img[row, col]\n",
    "            if row != 0:\n",
    "                new_val += img[row - 1, col]\n",
    "            if col != 0:\n",
    "                new_val += img[row, col - 1]\n",
    "            if row != 0 and col != 0:\n",
    "                new_val -= img[row - 1, col - 1]\n",
    "            img[row, col] = new_val\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  7 12]\n",
      " [ 8 16 24]\n",
      " [13 23 36]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([\n",
    "    [5, 2, 5],\n",
    "    [3, 6, 3],\n",
    "    [5, 2, 5]\n",
    "])\n",
    "\n",
    "print(to_integral_img(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViolaJonesClassifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69 µs, sys: 1e+03 ns, total: 70 µs\n",
      "Wall time: 77.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = ViolaJonesClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ensembles.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
