{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r43hj6t5Vr4V"
   },
   "source": [
    "The following model is the standard GAN which is part of **Exercise 1**. It is a very simple example and you can improve it by adding convolutions and many other ideas that we talked about if you want. Fill in the missing pieces and train it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypx0FAhePdvE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/50] [Batch 0/938] [D loss: 0.682676] [G loss: 0.709050]\n",
      "[Epoch 1/50] [Batch 200/938] [D loss: 0.566229] [G loss: 0.856968]\n",
      "[Epoch 1/50] [Batch 400/938] [D loss: 0.807519] [G loss: 0.433746]\n",
      "[Epoch 1/50] [Batch 600/938] [D loss: 0.496054] [G loss: 1.077175]\n",
      "[Epoch 1/50] [Batch 800/938] [D loss: 0.577621] [G loss: 1.605823]\n",
      "[Epoch 2/50] [Batch 0/938] [D loss: 0.438962] [G loss: 1.527040]\n",
      "[Epoch 2/50] [Batch 200/938] [D loss: 0.599387] [G loss: 2.615825]\n",
      "[Epoch 2/50] [Batch 400/938] [D loss: 0.456024] [G loss: 1.240072]\n",
      "[Epoch 2/50] [Batch 600/938] [D loss: 0.444105] [G loss: 1.262440]\n",
      "[Epoch 2/50] [Batch 800/938] [D loss: 0.581124] [G loss: 1.980942]\n",
      "[Epoch 3/50] [Batch 0/938] [D loss: 0.487133] [G loss: 1.328975]\n",
      "[Epoch 3/50] [Batch 200/938] [D loss: 0.599038] [G loss: 0.674074]\n",
      "[Epoch 3/50] [Batch 400/938] [D loss: 0.508071] [G loss: 2.584096]\n",
      "[Epoch 3/50] [Batch 600/938] [D loss: 0.370612] [G loss: 1.616733]\n",
      "[Epoch 3/50] [Batch 800/938] [D loss: 0.429238] [G loss: 1.512800]\n",
      "[Epoch 4/50] [Batch 0/938] [D loss: 0.531055] [G loss: 2.019109]\n",
      "[Epoch 4/50] [Batch 200/938] [D loss: 0.399403] [G loss: 1.488622]\n",
      "[Epoch 4/50] [Batch 400/938] [D loss: 0.410577] [G loss: 1.432762]\n",
      "[Epoch 4/50] [Batch 600/938] [D loss: 0.417408] [G loss: 1.930316]\n",
      "[Epoch 4/50] [Batch 800/938] [D loss: 0.395185] [G loss: 1.448418]\n",
      "[Epoch 5/50] [Batch 0/938] [D loss: 0.381490] [G loss: 1.570141]\n",
      "[Epoch 5/50] [Batch 200/938] [D loss: 0.597481] [G loss: 0.615350]\n",
      "[Epoch 5/50] [Batch 400/938] [D loss: 0.419604] [G loss: 1.740148]\n",
      "[Epoch 5/50] [Batch 600/938] [D loss: 0.424666] [G loss: 1.704190]\n",
      "[Epoch 5/50] [Batch 800/938] [D loss: 0.385947] [G loss: 1.474833]\n",
      "[Epoch 6/50] [Batch 0/938] [D loss: 0.457829] [G loss: 2.390565]\n",
      "[Epoch 6/50] [Batch 200/938] [D loss: 0.466488] [G loss: 1.641017]\n",
      "[Epoch 6/50] [Batch 400/938] [D loss: 0.505171] [G loss: 2.582176]\n",
      "[Epoch 6/50] [Batch 600/938] [D loss: 0.452974] [G loss: 1.343079]\n",
      "[Epoch 6/50] [Batch 800/938] [D loss: 0.443319] [G loss: 1.524688]\n",
      "[Epoch 7/50] [Batch 0/938] [D loss: 0.378050] [G loss: 1.628822]\n",
      "[Epoch 7/50] [Batch 200/938] [D loss: 0.597882] [G loss: 2.524407]\n",
      "[Epoch 7/50] [Batch 400/938] [D loss: 0.476620] [G loss: 2.113996]\n",
      "[Epoch 7/50] [Batch 600/938] [D loss: 0.458621] [G loss: 1.169754]\n",
      "[Epoch 7/50] [Batch 800/938] [D loss: 0.412541] [G loss: 1.014874]\n",
      "[Epoch 8/50] [Batch 0/938] [D loss: 0.580821] [G loss: 2.244788]\n",
      "[Epoch 8/50] [Batch 200/938] [D loss: 0.385571] [G loss: 1.158393]\n",
      "[Epoch 8/50] [Batch 400/938] [D loss: 0.527629] [G loss: 0.874781]\n",
      "[Epoch 8/50] [Batch 600/938] [D loss: 0.469620] [G loss: 1.047704]\n",
      "[Epoch 8/50] [Batch 800/938] [D loss: 0.498269] [G loss: 0.834879]\n",
      "[Epoch 9/50] [Batch 0/938] [D loss: 0.475101] [G loss: 1.316689]\n",
      "[Epoch 9/50] [Batch 200/938] [D loss: 0.455828] [G loss: 1.588006]\n",
      "[Epoch 9/50] [Batch 400/938] [D loss: 0.493999] [G loss: 1.821279]\n",
      "[Epoch 9/50] [Batch 600/938] [D loss: 0.461274] [G loss: 2.211810]\n",
      "[Epoch 9/50] [Batch 800/938] [D loss: 0.467343] [G loss: 1.124271]\n",
      "[Epoch 10/50] [Batch 0/938] [D loss: 0.456410] [G loss: 1.689431]\n",
      "[Epoch 10/50] [Batch 200/938] [D loss: 0.519963] [G loss: 1.560733]\n",
      "[Epoch 10/50] [Batch 400/938] [D loss: 0.453100] [G loss: 1.582911]\n",
      "[Epoch 10/50] [Batch 600/938] [D loss: 0.585182] [G loss: 0.753187]\n",
      "[Epoch 10/50] [Batch 800/938] [D loss: 0.454651] [G loss: 1.442384]\n",
      "[Epoch 11/50] [Batch 0/938] [D loss: 0.430038] [G loss: 1.449530]\n",
      "[Epoch 11/50] [Batch 200/938] [D loss: 0.429509] [G loss: 1.310699]\n",
      "[Epoch 11/50] [Batch 400/938] [D loss: 0.470936] [G loss: 1.058370]\n",
      "[Epoch 11/50] [Batch 600/938] [D loss: 0.529883] [G loss: 0.847258]\n",
      "[Epoch 11/50] [Batch 800/938] [D loss: 0.456630] [G loss: 1.641700]\n",
      "[Epoch 12/50] [Batch 0/938] [D loss: 0.511715] [G loss: 2.055400]\n",
      "[Epoch 12/50] [Batch 200/938] [D loss: 0.562069] [G loss: 0.886121]\n",
      "[Epoch 12/50] [Batch 400/938] [D loss: 0.451496] [G loss: 1.147166]\n",
      "[Epoch 12/50] [Batch 600/938] [D loss: 0.460841] [G loss: 1.641435]\n",
      "[Epoch 12/50] [Batch 800/938] [D loss: 0.621722] [G loss: 0.580762]\n",
      "[Epoch 13/50] [Batch 0/938] [D loss: 0.524103] [G loss: 1.552851]\n",
      "[Epoch 13/50] [Batch 200/938] [D loss: 0.543119] [G loss: 1.726861]\n",
      "[Epoch 13/50] [Batch 400/938] [D loss: 0.534694] [G loss: 0.916562]\n",
      "[Epoch 13/50] [Batch 600/938] [D loss: 0.440471] [G loss: 1.583577]\n",
      "[Epoch 13/50] [Batch 800/938] [D loss: 0.485659] [G loss: 1.309259]\n",
      "[Epoch 14/50] [Batch 0/938] [D loss: 0.572893] [G loss: 0.741487]\n",
      "[Epoch 14/50] [Batch 200/938] [D loss: 0.529747] [G loss: 0.964276]\n",
      "[Epoch 14/50] [Batch 400/938] [D loss: 0.583124] [G loss: 2.121787]\n",
      "[Epoch 14/50] [Batch 600/938] [D loss: 0.455744] [G loss: 1.620845]\n",
      "[Epoch 14/50] [Batch 800/938] [D loss: 0.457479] [G loss: 1.096446]\n",
      "[Epoch 15/50] [Batch 0/938] [D loss: 0.508928] [G loss: 1.345916]\n",
      "[Epoch 15/50] [Batch 200/938] [D loss: 0.556430] [G loss: 1.758388]\n",
      "[Epoch 15/50] [Batch 400/938] [D loss: 0.548600] [G loss: 0.742907]\n",
      "[Epoch 15/50] [Batch 600/938] [D loss: 0.523609] [G loss: 1.906462]\n",
      "[Epoch 15/50] [Batch 800/938] [D loss: 0.461907] [G loss: 1.659728]\n",
      "[Epoch 16/50] [Batch 0/938] [D loss: 0.487754] [G loss: 1.050626]\n",
      "[Epoch 16/50] [Batch 200/938] [D loss: 0.578735] [G loss: 2.104447]\n",
      "[Epoch 16/50] [Batch 400/938] [D loss: 0.621187] [G loss: 2.078090]\n",
      "[Epoch 16/50] [Batch 600/938] [D loss: 0.493932] [G loss: 2.024080]\n",
      "[Epoch 16/50] [Batch 800/938] [D loss: 0.454513] [G loss: 1.575827]\n",
      "[Epoch 17/50] [Batch 0/938] [D loss: 0.618326] [G loss: 2.100430]\n",
      "[Epoch 17/50] [Batch 200/938] [D loss: 0.498497] [G loss: 1.494584]\n",
      "[Epoch 17/50] [Batch 400/938] [D loss: 0.440336] [G loss: 1.798213]\n",
      "[Epoch 17/50] [Batch 600/938] [D loss: 0.513639] [G loss: 1.035950]\n",
      "[Epoch 17/50] [Batch 800/938] [D loss: 0.516549] [G loss: 2.080326]\n",
      "[Epoch 18/50] [Batch 0/938] [D loss: 0.502429] [G loss: 2.098145]\n",
      "[Epoch 18/50] [Batch 200/938] [D loss: 0.490450] [G loss: 1.732104]\n",
      "[Epoch 18/50] [Batch 400/938] [D loss: 0.557304] [G loss: 1.458000]\n",
      "[Epoch 18/50] [Batch 600/938] [D loss: 0.427153] [G loss: 1.666597]\n",
      "[Epoch 18/50] [Batch 800/938] [D loss: 0.470035] [G loss: 1.865059]\n",
      "[Epoch 19/50] [Batch 0/938] [D loss: 0.457988] [G loss: 1.857460]\n",
      "[Epoch 19/50] [Batch 200/938] [D loss: 0.480730] [G loss: 1.330278]\n",
      "[Epoch 19/50] [Batch 400/938] [D loss: 0.599407] [G loss: 2.299152]\n",
      "[Epoch 19/50] [Batch 600/938] [D loss: 0.492050] [G loss: 1.286103]\n",
      "[Epoch 19/50] [Batch 800/938] [D loss: 0.552617] [G loss: 1.775934]\n",
      "[Epoch 20/50] [Batch 0/938] [D loss: 0.487171] [G loss: 1.704005]\n",
      "[Epoch 20/50] [Batch 200/938] [D loss: 0.508851] [G loss: 1.146120]\n",
      "[Epoch 20/50] [Batch 400/938] [D loss: 0.606780] [G loss: 1.969149]\n",
      "[Epoch 20/50] [Batch 600/938] [D loss: 0.466030] [G loss: 1.677834]\n",
      "[Epoch 20/50] [Batch 800/938] [D loss: 0.443530] [G loss: 1.588408]\n",
      "[Epoch 21/50] [Batch 0/938] [D loss: 0.518781] [G loss: 1.599622]\n",
      "[Epoch 21/50] [Batch 200/938] [D loss: 0.497147] [G loss: 1.385468]\n",
      "[Epoch 21/50] [Batch 400/938] [D loss: 0.467526] [G loss: 1.442936]\n",
      "[Epoch 21/50] [Batch 600/938] [D loss: 0.571015] [G loss: 0.832968]\n",
      "[Epoch 21/50] [Batch 800/938] [D loss: 0.499495] [G loss: 1.671274]\n",
      "[Epoch 22/50] [Batch 0/938] [D loss: 0.428379] [G loss: 1.394947]\n",
      "[Epoch 22/50] [Batch 200/938] [D loss: 0.428996] [G loss: 1.632242]\n",
      "[Epoch 22/50] [Batch 400/938] [D loss: 0.518839] [G loss: 2.172413]\n",
      "[Epoch 22/50] [Batch 600/938] [D loss: 0.416575] [G loss: 1.811197]\n",
      "[Epoch 22/50] [Batch 800/938] [D loss: 0.406843] [G loss: 1.774222]\n",
      "[Epoch 23/50] [Batch 0/938] [D loss: 0.617493] [G loss: 2.471065]\n",
      "[Epoch 23/50] [Batch 200/938] [D loss: 0.470983] [G loss: 1.218055]\n",
      "[Epoch 23/50] [Batch 400/938] [D loss: 0.476896] [G loss: 1.155172]\n",
      "[Epoch 23/50] [Batch 600/938] [D loss: 0.534120] [G loss: 0.822098]\n",
      "[Epoch 23/50] [Batch 800/938] [D loss: 0.459748] [G loss: 1.039576]\n",
      "[Epoch 24/50] [Batch 0/938] [D loss: 0.478104] [G loss: 1.316800]\n",
      "[Epoch 24/50] [Batch 200/938] [D loss: 0.483039] [G loss: 1.301179]\n",
      "[Epoch 24/50] [Batch 400/938] [D loss: 0.535772] [G loss: 1.056477]\n",
      "[Epoch 24/50] [Batch 600/938] [D loss: 0.549664] [G loss: 0.840728]\n",
      "[Epoch 24/50] [Batch 800/938] [D loss: 0.524733] [G loss: 1.182803]\n",
      "[Epoch 25/50] [Batch 0/938] [D loss: 0.544642] [G loss: 1.990989]\n",
      "[Epoch 25/50] [Batch 200/938] [D loss: 0.420386] [G loss: 1.531256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/50] [Batch 400/938] [D loss: 0.515128] [G loss: 1.697827]\n",
      "[Epoch 25/50] [Batch 600/938] [D loss: 0.480215] [G loss: 1.701632]\n",
      "[Epoch 25/50] [Batch 800/938] [D loss: 0.434877] [G loss: 1.327255]\n",
      "[Epoch 26/50] [Batch 0/938] [D loss: 0.496443] [G loss: 1.193023]\n",
      "[Epoch 26/50] [Batch 200/938] [D loss: 0.426083] [G loss: 1.162979]\n",
      "[Epoch 26/50] [Batch 400/938] [D loss: 0.501156] [G loss: 1.425578]\n",
      "[Epoch 26/50] [Batch 600/938] [D loss: 0.440134] [G loss: 1.322614]\n",
      "[Epoch 26/50] [Batch 800/938] [D loss: 0.499348] [G loss: 1.816809]\n",
      "[Epoch 27/50] [Batch 0/938] [D loss: 0.512640] [G loss: 1.465984]\n",
      "[Epoch 27/50] [Batch 200/938] [D loss: 0.441508] [G loss: 1.600295]\n",
      "[Epoch 27/50] [Batch 400/938] [D loss: 0.513211] [G loss: 1.407165]\n",
      "[Epoch 27/50] [Batch 600/938] [D loss: 0.474057] [G loss: 1.356120]\n",
      "[Epoch 27/50] [Batch 800/938] [D loss: 0.545602] [G loss: 0.793062]\n",
      "[Epoch 28/50] [Batch 0/938] [D loss: 0.516948] [G loss: 1.860915]\n",
      "[Epoch 28/50] [Batch 200/938] [D loss: 0.480711] [G loss: 1.847753]\n",
      "[Epoch 28/50] [Batch 400/938] [D loss: 0.469312] [G loss: 1.355642]\n",
      "[Epoch 28/50] [Batch 600/938] [D loss: 0.464131] [G loss: 1.446523]\n",
      "[Epoch 28/50] [Batch 800/938] [D loss: 0.482307] [G loss: 1.705178]\n",
      "[Epoch 29/50] [Batch 0/938] [D loss: 0.626042] [G loss: 2.450992]\n",
      "[Epoch 29/50] [Batch 200/938] [D loss: 0.443139] [G loss: 1.849339]\n",
      "[Epoch 29/50] [Batch 400/938] [D loss: 0.596766] [G loss: 1.995440]\n",
      "[Epoch 29/50] [Batch 600/938] [D loss: 0.488605] [G loss: 1.284291]\n",
      "[Epoch 29/50] [Batch 800/938] [D loss: 0.471714] [G loss: 1.570213]\n",
      "[Epoch 30/50] [Batch 0/938] [D loss: 0.557601] [G loss: 2.249535]\n",
      "[Epoch 30/50] [Batch 200/938] [D loss: 0.512584] [G loss: 1.699704]\n",
      "[Epoch 30/50] [Batch 400/938] [D loss: 0.446951] [G loss: 1.651269]\n",
      "[Epoch 30/50] [Batch 600/938] [D loss: 0.490669] [G loss: 1.274417]\n",
      "[Epoch 30/50] [Batch 800/938] [D loss: 0.592265] [G loss: 0.815794]\n",
      "[Epoch 31/50] [Batch 0/938] [D loss: 0.526525] [G loss: 1.850294]\n",
      "[Epoch 31/50] [Batch 200/938] [D loss: 0.518554] [G loss: 2.011274]\n",
      "[Epoch 31/50] [Batch 400/938] [D loss: 0.479166] [G loss: 1.258174]\n",
      "[Epoch 31/50] [Batch 600/938] [D loss: 0.447464] [G loss: 1.136542]\n",
      "[Epoch 31/50] [Batch 800/938] [D loss: 0.475221] [G loss: 1.128735]\n",
      "[Epoch 32/50] [Batch 0/938] [D loss: 0.501068] [G loss: 1.531128]\n",
      "[Epoch 32/50] [Batch 200/938] [D loss: 0.474490] [G loss: 1.034348]\n",
      "[Epoch 32/50] [Batch 400/938] [D loss: 0.512134] [G loss: 0.917963]\n",
      "[Epoch 32/50] [Batch 600/938] [D loss: 0.471828] [G loss: 1.274040]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "os.makedirs(\"images_gan\", exist_ok=True)\n",
    "os.makedirs(\"images_cgan\", exist_ok=True)\n",
    "\n",
    "n_epochs = 50                                  #number of epochs of training\n",
    "batch_size = 64                                #size of the batches\n",
    "lr = 0.0002                                    #adam: learning rate\n",
    "b1 = 0.5                                       #adam: decay of first order momentum of gradient\n",
    "b2 = 0.999                                     #adam: decay of second order momentum of gradient\n",
    "n_cpu = multiprocessing.cpu_count()            #number of cpu threads to use during batch generation\n",
    "latent_dim = 100                               #dimensionality of the latent space\n",
    "img_size = 28                                  #size of each image dimension\n",
    "channels = 1                                   #number of image channels\n",
    "sample_interval = 400                          #interval between image samples\n",
    "\n",
    "\n",
    "img_shape = (channels, img_size, img_size)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "\n",
    "# Loss function\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "bce_loss.to(device)\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs(\"./mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        real_imgs =  imgs.to(device)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        z = torch.randn((imgs.shape[0], latent_dim)).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        y_pred_fake = discriminator(gen_imgs)\n",
    "        \n",
    "        g_loss = bce_loss(y_pred_fake, torch.zeros_like(y_pred_fake))\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        \n",
    "        gen_imgs = generator(z)\n",
    "        \n",
    "        y_pred_real = discriminator(real_imgs)\n",
    "        y_pred_fake = discriminator(gen_imgs)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_loss = bce_loss(y_pred_real, torch.zeros_like(y_pred_real))\n",
    "        fake_loss = bce_loss(y_pred_fake, torch.ones_like(y_pred_real))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        if i % 200 == 0:\n",
    "            print(\n",
    "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "              % (epoch+1, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            # You can also safe samples in your drive & maybe save your network as well\n",
    "            save_image(gen_imgs.data[:25], \"images_gan/GAN-%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((imgs.shape[0], latent_dim)).to(device)\n",
    "\n",
    "# Generate a batch of images\n",
    "with torch.no_grad():\n",
    "    gen_imgs = generator(z)\n",
    "    \n",
    "plt.imshow(gen_imgs.cpu().numpy()[0].reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifer(nn.Module):\n",
    "    def __init__(self, in_dims):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dims, 16, kernel_size=(3, 3), padding=1, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), padding=1, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1, stride=2)\n",
    "        self.dense1 = nn.Linear(4 * 4 * 64, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = x.view(-1, 4 * 4 * 64)\n",
    "        x = self.dense1(x)\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "clf = Classifer(1).to(device)\n",
    "\n",
    "clf_optim = torch.optim.Adam(clf.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "for epoch in range(1, 4):\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    iterations = 0\n",
    "    for i, (x, y) in enumerate(dataloader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        clf_optim.zero_grad()\n",
    "        y_pred = clf(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        clf_optim.step()\n",
    "        running_loss += loss.item()\n",
    "        iterations += 1\n",
    "        with torch.no_grad():\n",
    "            accuracy = torch.mean(((torch.argmax(y_pred, 1) == y) * 1).float())\n",
    "            running_accuracy += accuracy.item()\n",
    "    loss = running_loss / iterations\n",
    "    acc = running_accuracy / iterations\n",
    "    print(f\"Epoch {epoch}/3 ==> train loss: {loss}, train acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((1000, latent_dim)).to(device)\n",
    "\n",
    "# Generate a batch of images\n",
    "with torch.no_grad():\n",
    "    gen_imgs = generator(z)\n",
    "    y_pred = clf(gen_imgs)\n",
    "    \n",
    "y_pred = np.argmax(y_pred.cpu().numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distributions = [np.sum(y_pred == i) for i in range(10)]\n",
    "print(class_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(list(range(10)), class_distributions, tick_label=list(range(10)))\n",
    "plt.ylabel(\"Number of predictions\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(digits, num_classes):\n",
    "    \"\"\" [[3]] => [[0, 0, 1]]\n",
    "    \"\"\"\n",
    "    labels_onehot = torch.zeros(digits.shape[0], num_classes).to(device)\n",
    "    labels_onehot.scatter_(1, digits.view(-1, 1), 1)\n",
    "    return labels_onehot\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + num_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        z =  torch.cat((z, y), dim=1)\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)) + num_classes, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, y):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        img_flat =  torch.cat((img_flat, y), dim=1)\n",
    "\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity\n",
    "\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator(10)\n",
    "discriminator = Discriminator(10)\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "bce_loss.to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, y) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        # We use the Cross Entropy (CE) loss. So we need labels. Define them here:\n",
    "        \"\"\"There is something missing here\"\"\"\n",
    "        \n",
    "        y = y.to(device)\n",
    "        y = to_onehot(y, 10)\n",
    "    \n",
    "        # Configure input\n",
    "        real_imgs =  imgs.to(device)\n",
    "\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = torch.randn((imgs.shape[0], latent_dim)).to(device)\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, y)\n",
    "        \n",
    "        y_pred_fake = discriminator(gen_imgs, y)\n",
    "        \n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = bce_loss(y_pred_fake, torch.zeros_like(y_pred_fake))\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        z = torch.randn((imgs.shape[0], latent_dim)).to(device)\n",
    "        \n",
    "        gen_imgs = generator(z, y)\n",
    "        \n",
    "        y_pred_real = discriminator(real_imgs, y)\n",
    "        y_pred_fake = discriminator(gen_imgs, y)\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = bce_loss(y_pred_real, torch.zeros_like(y_pred_real))\n",
    "        fake_loss = bce_loss(y_pred_fake, torch.ones_like(y_pred_real))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        if i%200 == 0:\n",
    "            print(\n",
    "              \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "              % (epoch+1, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            # You can also safe samples in your drive & maybe save your network as well\n",
    "            save_image(gen_imgs.data[:25], \"images_cgan/GAN-%d.png\" % batches_done, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((1000, latent_dim)).to(device)\n",
    "\n",
    "y = [i % 100 for i in range(1000)]\n",
    "\n",
    "# Generate a batch of images\n",
    "with torch.no_grad():\n",
    "    y = torch.LongTensor([i % 10 for i in range(1000)]).to(device)\n",
    "    y = to_onehot(y, 10)\n",
    "    gen_imgs = generator(z, y)\n",
    "    y_pred = clf(gen_imgs)\n",
    "    \n",
    "y_pred = np.argmax(y_pred.cpu().numpy(), axis=1)\n",
    "\n",
    "class_distributions = [np.sum(y_pred == i) for i in range(10)]\n",
    "print(class_distributions)\n",
    "\n",
    "plt.bar(list(range(10)), class_distributions, tick_label=list(range(10)))\n",
    "plt.ylabel(\"Number of predictions\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GAN_starter_kit.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
