{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=multiprocessing.cpu_count())\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on gpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Training on gpu\")\n",
    "    mode = 'cuda'\n",
    "else:\n",
    "    print(\"Training on cpu\")\n",
    "    mode = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1. Convolutional Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, is_last):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 3), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1), bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        if is_last:\n",
    "            self.conv4 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1), stride=(2, 2), bias=False)\n",
    "        else:\n",
    "            self.conv4 = nn.Conv2d(out_channels, out_channels, kernel_size=(3, 3), padding=(1, 1), stride=(1, 1), bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.upsample_filters = True\n",
    "            self.transform_skip_conv = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), padding=(0, 0), stride=(1, 1), bias=False)\n",
    "            self.transform_skip_bn   = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.upsample_filters = False\n",
    "        if is_last:\n",
    "            self.transform_skip_conv = nn.Conv2d(out_channels, out_channels, kernel_size=(1, 1), padding=(0, 0), stride=(2, 2), bias=False)\n",
    "            self.transform_skip_bn = nn.BatchNorm2d(out_channels)\n",
    "        self.is_last = is_last\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_skip = x\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.upsample_filters:\n",
    "            x_skip = self.transform_skip_conv(x_skip)\n",
    "            x_skip = torch.nn.functional.relu(x_skip)\n",
    "            x_skip = self.transform_skip_bn(x_skip)\n",
    "        \n",
    "        x = x + x_skip\n",
    "        x_skip = x\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        if self.is_last:\n",
    "            x_skip = self.transform_skip_conv(x_skip)\n",
    "            x_skip = torch.nn.functional.relu(x_skip)\n",
    "            x_skip = self.transform_skip_bn(x_skip)\n",
    "        \n",
    "        x = x + x_skip\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(ResNetBasicBlock(in_channels, out_channels, is_last=False))\n",
    "        for j in range(2 * n - 2):\n",
    "            layers.append(ResNetBasicBlock(out_channels, out_channels, is_last=False))\n",
    "        layers.append(ResNetBasicBlock(out_channels, out_channels, is_last=True))\n",
    "        self.seq = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, n):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=(3, 3), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.rn_block1 = ResNetBlock(16, 16 * (2 ** 0), n)\n",
    "        self.rn_block2 = ResNetBlock(16 * (2 ** 0), 16 * (2 ** 1), n) \n",
    "        self.rn_block3 = ResNetBlock(16 * (2 ** 1), 16 * (2 ** 2), n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.rn_block1(x)\n",
    "        x = self.rn_block2(x)\n",
    "        x = self.rn_block3(x)\n",
    "        x = self.flatten(x) \n",
    "        x = self.fc(x)\n",
    "        x = torch.nn.functional.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "        \n",
    "clf = ResNet(in_channels=3, n=1).to(mode)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(clf.parameters(), lr=0.002, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.87it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 65.43it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 1: 2.165030762362663\n",
      "val loss at epoch 1: 2.0518578185310847\n",
      "train acc at epoch 1: 0.2894221547314578\n",
      "val acc at epoch 1: 0.409315664556962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.49it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.96it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 2: 2.0046993344641098\n",
      "val loss at epoch 2: 1.9659567060349863\n",
      "train acc at epoch 2: 0.46051390664961633\n",
      "val acc at epoch 2: 0.5032634493670886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:13<00:00, 29.93it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.73it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 3: 1.9355430301193082\n",
      "val loss at epoch 3: 1.9235815473749667\n",
      "train acc at epoch 3: 0.5323049872122761\n",
      "val acc at epoch 3: 0.5409414556962026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.30it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 62.79it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 4: 1.8892743136266918\n",
      "val loss at epoch 4: 1.8941476345062256\n",
      "train acc at epoch 4: 0.5788043478260869\n",
      "val acc at epoch 4: 0.5706091772151899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.23it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 65.26it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 5: 1.8512547653349465\n",
      "val loss at epoch 5: 1.8727712540686885\n",
      "train acc at epoch 5: 0.6188459079283888\n",
      "val acc at epoch 5: 0.5900909810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.28it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.33it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 6: 1.8205131176487563\n",
      "val loss at epoch 6: 1.856243285951735\n",
      "train acc at epoch 6: 0.6506034207161125\n",
      "val acc at epoch 6: 0.6081882911392406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.54it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.95it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 7: 1.7942005316619678\n",
      "val loss at epoch 7: 1.8461398157892348\n",
      "train acc at epoch 7: 0.6766783887468031\n",
      "val acc at epoch 7: 0.6203520569620253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.97it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.81it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 8: 1.7697113917001983\n",
      "val loss at epoch 8: 1.8312387345712395\n",
      "train acc at epoch 8: 0.703684462915601\n",
      "val acc at epoch 8: 0.6329113924050633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.23it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.17it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 9: 1.748166630030288\n",
      "val loss at epoch 9: 1.8241908791698986\n",
      "train acc at epoch 9: 0.7260070332480818\n",
      "val acc at epoch 9: 0.638943829113924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.32it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.15it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 10: 1.7289032103765347\n",
      "val loss at epoch 10: 1.8158510093447529\n",
      "train acc at epoch 10: 0.745696131713555\n",
      "val acc at epoch 10: 0.6498219936708861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.11it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.92it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 11: 1.7077490033396066\n",
      "val loss at epoch 11: 1.81572524958019\n",
      "train acc at epoch 11: 0.7680226982097187\n",
      "val acc at epoch 11: 0.6488330696202531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.88it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.73it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 12: 1.6908708996784962\n",
      "val loss at epoch 12: 1.80819847915746\n",
      "train acc at epoch 12: 0.7845348465473146\n",
      "val acc at epoch 12: 0.6573378164556962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.17it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 65.75it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 13: 1.673906671421607\n",
      "val loss at epoch 13: 1.8078153736983673\n",
      "train acc at epoch 13: 0.8019301470588235\n",
      "val acc at epoch 13: 0.6556566455696202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.49it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.47it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 14: 1.6581817944641308\n",
      "val loss at epoch 14: 1.80682488181923\n",
      "train acc at epoch 14: 0.8177709398976982\n",
      "val acc at epoch 14: 0.6599090189873418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.42it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 58.86it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 15: 1.6433354616165161\n",
      "val loss at epoch 15: 1.7990447961831395\n",
      "train acc at epoch 15: 0.8322650255754475\n",
      "val acc at epoch 15: 0.6620846518987342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:13<00:00, 30.00it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 65.80it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 16: 1.6310924206243451\n",
      "val loss at epoch 16: 1.801504390149177\n",
      "train acc at epoch 16: 0.8437260230179029\n",
      "val acc at epoch 16: 0.6613924050632911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.33it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 65.91it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 17: 1.6195075603397302\n",
      "val loss at epoch 17: 1.7992937278143968\n",
      "train acc at epoch 17: 0.8553908248081841\n",
      "val acc at epoch 17: 0.6624802215189873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.63it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 65.79it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 18: 1.6083376316158362\n",
      "val loss at epoch 18: 1.794998967194859\n",
      "train acc at epoch 18: 0.8657368925831203\n",
      "val acc at epoch 18: 0.6682159810126582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.32it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.01it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss at epoch 19: 1.5970504698546037\n",
      "val loss at epoch 19: 1.7948844674267346\n",
      "train acc at epoch 19: 0.8761468989769822\n",
      "val acc at epoch 19: 0.6678204113924051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 304/391 [00:09<00:02, 31.75it/s]"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # epoch\n",
    "    total_train_loss = 0\n",
    "    total_train_acc = 0\n",
    "    train_iterations = 0\n",
    "    for x, y in tqdm(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to(mode), y.to(mode)\n",
    "        y_pred = clf(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        acc = (torch.argmax(y_pred, dim=1) == y).sum().item() / y.shape[0]\n",
    "        total_train_acc += acc\n",
    "        train_iterations += 1\n",
    "\n",
    "    total_val_loss = 0\n",
    "    total_val_acc = 0\n",
    "    test_iterations = 0\n",
    "    for x, y in tqdm(testloader):\n",
    "        x, y = x.to(mode), y.to(mode)\n",
    "        with torch.no_grad():\n",
    "            y_pred = clf(x)\n",
    "            acc = (torch.argmax(y_pred, dim=1) == y).sum().item() / y.shape[0]\n",
    "            loss = criterion(y_pred, y)\n",
    "            total_val_acc += acc\n",
    "            total_val_loss += loss.item()\n",
    "        test_iterations += 1\n",
    "    \n",
    "    \n",
    "    train_losses.append(total_train_loss / train_iterations)\n",
    "    train_accs.append(total_train_acc / train_iterations)\n",
    "    val_losses.append(total_val_loss / test_iterations)\n",
    "    val_accs.append(total_val_acc / test_iterations)\n",
    "    \n",
    "    print(f\"train loss at epoch {epoch}: {train_losses[-1]}\")\n",
    "    print(f\"val loss at epoch {epoch}: {val_losses[-1]}\")\n",
    "    print(f\"train acc at epoch {epoch}: {train_accs[-1]}\")\n",
    "    print(f\"val acc at epoch {epoch}: {val_accs[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(train_losses))), train_losses, label=\"training set\")\n",
    "plt.plot(list(range(len(val_losses))), val_losses, label=\"validation set\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(train_accs))), train_accs, label=\"training set\")\n",
    "plt.plot(list(range(len(val_accs))), val_accs, label=\"validation set\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Plot the filters of the first layer. What kind of features do they extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = clf.conv1.weight.detach().cpu().clone().numpy()\n",
    "\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 4\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = filters[i - 1]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Is deeper always better? Provide some evidence for your answer and explain why that is the case.\n",
    "\n",
    "In theory it should be better, since our network can learn more complex functions, however in practise it makes the network overfit faster, makes the network suffer from the vanishing gradient problem and increases computational complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
